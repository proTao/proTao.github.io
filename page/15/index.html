<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>proTao的大脑具现</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="proTao的大脑具现">
<meta property="og:url" content="https://protao.github.io/page/15/index.html">
<meta property="og:site_name" content="proTao的大脑具现">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="proTao的大脑具现">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="../../css/style.css">
  <meta name="baidu-site-verification" content="xerEdoxBbf">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)'],['$$$','$$$'],['$','$']]}
});
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../index.html" id="logo">proTao的大脑具现</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../index.html">home</a>
        
          <a class="main-nav-link" href="../../archives">archives</a>
        
          <a class="main-nav-link" href="../../about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://protao.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    

<article id="post-Python-2018-06-03-PyStringObject" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2018/06/03/Python-2018-06-03-PyStringObject/" class="article-date">
  <time datetime="2018-06-02T16:00:00.000Z" itemprop="datePublished">2018-06-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/06/03/Python-2018-06-03-PyStringObject/">python中的字符串对象</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-PyStringObject-与-PyString-Type"><a href="#1-PyStringObject-与-PyString-Type" class="headerlink" title="1. PyStringObject 与 PyString_Type"></a>1. PyStringObject 与 PyString_Type</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[stringobject.h]</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">	PyObject_VAR_HEAD</span><br><span class="line">	<span class="keyword">long</span> ob_shash;</span><br><span class="line">	<span class="keyword">int</span> ob_sstate;</span><br><span class="line">	<span class="keyword">char</span> ob_sval[<span class="number">1</span>];</span><br><span class="line">&#125; PyStringObject;</span><br></pre></td></tr></table></figure>
<p><code>PyStringObject</code>是变长对象中的不可变对象。当创建了一个<code>PyStringObject</code>对象之后,该对象内部维护的字符串就不能再被改变了。这一点特性使得 <code>PyStringObject</code> 对象能作为 <code>PyDictObject</code> 的键值,但同时也使得一些字符串操作的效率大大降低,比如多个字符串的连接操<br>作。</p>
<p><code>ob_sval</code>是存放实际字符串的数组，数组长度是<code>ob_size+1</code>，因为里面存放的是原生C字符串，需要一个额外的结束符。但是注意，申请的时候令数组长度为1，实际上是为了要数组的首地址当做指针来用，<code>ob_sval</code> 作为首地址，在字符串申请函数中，申请的是一段长度为<code>ob_size+1</code>个字节的内存,而且必须满足 <code>ob_sval[ob_size] = &quot;\0‟</code>。详见后面源码与图一。</p>
<p><img src="/img/PyStringObject1.png" alt="PyStringObject存储结构"></p>
<p><code>PyStringObject</code> 中的 <code>ob_shash</code> 变量其作用是缓存该对象的 HASH 值,这样可以避免每一次都重新计算该字符串对象的 HASH 值。如果一个 <code>PyStringObject</code>对象还没有被计算过 HASH 值,那么 <code>ob_shash</code> 的初始值是-1。<code>PyStringObject</code> 对象的 <code>ob_sstate</code> 变量该对象是否被 <code>Intern</code> 的标志。</p>
<p>需要注意的是,字符串类型对象的<code>tp_as_number</code>,<code>tp_as_sequence</code>,<code>tp_as_mapping</code>,<br>三个域都被设置了。这表示<code>PyStringObject</code>对数值操作,序列操作和映射操作都支持。</p>
        
          <p class="article-more-link">
            <a href="../../2018/06/03/Python-2018-06-03-PyStringObject/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/06/03/Python-2018-06-03-PyStringObject/" data-id="cjxo5e6pq0031z16dwc2gv7ls" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-Python-2018-06-02-PyIntObject" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2018/06/02/Python-2018-06-02-PyIntObject/" class="article-date">
  <time datetime="2018-06-01T16:00:00.000Z" itemprop="datePublished">2018-06-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/06/02/Python-2018-06-02-PyIntObject/">python中的整数对象</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-初识-PyIntObject-对象"><a href="#1-初识-PyIntObject-对象" class="headerlink" title="1. 初识 PyIntObject 对象"></a>1. 初识 PyIntObject 对象</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intobject.h]</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">	PyObject_HEAD</span><br><span class="line">    <span class="keyword">long</span> ob_ival;</span><br><span class="line">&#125; PyIntObject</span><br></pre></td></tr></table></figure>
<p>首先，<code>PyIntObject</code>是一个不可变（immutable）对象。其次，Python内部也大量的使用整数对象，我们在自己的代码中也会有大量的创建销毁整型对象的操作，因此单独的维护整形对象并对其申请内存和释放内存是不现实的。Python给出的解决方案是将整形对象通过一定的结构连接在一起的<strong>整数对象系统</strong>：整数对象池，一个整形对象的缓冲池机制。</p>
<p>Python的实现中，对某些可能频繁执行的代码，都会提供函数和宏两个版本。<strong>宏版本节省了一次函数调用的开销但是牺牲了类型安全。</strong>对于<code>PyIntObject</code>的操作，像前面说的，定义在该类型对象的函数指针中。特别注意的是，<code>tp_as_number</code>指针存放的是<code>int_as_number</code>结构体的地址，在 python2.5 中，该结构体包含了39个<code>PyNumberMethods</code>要求的函数指针，但是不是每个指针都有定义，部分为<code>NULL</code>。</p>
<p>另一个有趣的元信息是对象的文档，这个元信息维护在<code>int_doc</code>域中，文档无缝集成在语言的实现中，这一点是Python相对其他语言的一大特点。</p>
        
          <p class="article-more-link">
            <a href="../../2018/06/02/Python-2018-06-02-PyIntObject/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/06/02/Python-2018-06-02-PyIntObject/" data-id="cjxo5e6pn0030z16devj3hjnl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-Python-2018-06-01-PyObject" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2018/06/01/Python-2018-06-01-PyObject/" class="article-date">
  <time datetime="2018-05-31T16:00:00.000Z" itemprop="datePublished">2018-06-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/python/">python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/06/01/Python-2018-06-01-PyObject/">python对象初探</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>!()[/img/cover/python_cover1.jpg]</p>
<h2 id="1-Python中的对象"><a href="#1-Python中的对象" class="headerlink" title="1. Python中的对象"></a>1. Python中的对象</h2><blockquote>
<p><strong>Python中一切皆是对象。</strong><br>                 ————Guido van Rossum(1989)</p>
</blockquote>
<p>这句话只要你学过python，你就很有可能在你的Python学习之旅的前30分钟就已经见过了，但是这句话具体是什么意思呢？</p>
<p>一句话来说，就是<strong>面向对象中的“类”和“对象”在Python中都是对象</strong>。类似于int对象的<strong>类型对象</strong>，实现了“类的概念”，对类型对象“实例化”得到的<strong>实例对象</strong>实现了“对象”这个概念。</p>
<p>通常的说法是,对象是数据以及基于这些数据的操作的集合。在计算机上,一个对象实际上就是一片被分配的内存空间,这些内存可能是连续的,也有可能是离散的,这都不重要,重要的是这片内存在更高的层次上可以作为一个整体来考虑,这个整体就是一个对象。在这片内存中,存储着一系列的数据以及可以对这些数据进行修改或读取的一系列操作的代码。</p>
<p><strong>在 Python 中,对象就是在堆上申请的结构体,对象不能是被静态初始化的,并且也不能是在栈空间上生存的。唯一的例外就是类型对象(type object),Python中所有的类型对象都是被静态初始化的。在 Python 中,一个对象一旦被创建,它在内存中的大小就是不变的了。</strong>这就意味着那些需要容纳可变长度数据的对象只能在对象内维护一个指向一个可变大小的内存区域的指针。</p>
        
          <p class="article-more-link">
            <a href="../../2018/06/01/Python-2018-06-01-PyObject/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/06/01/Python-2018-06-01-PyObject/" data-id="cjxo5e6pi002yz16dbrpaz9hb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-机器学习-2018-05-30-GMM" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2018/05/30/机器学习-2018-05-30-GMM/" class="article-date">
  <time datetime="2018-05-29T16:00:00.000Z" itemprop="datePublished">2018-05-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/05/30/机器学习-2018-05-30-GMM/">GMM模型原理与实践</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-模型"><a href="#1-模型" class="headerlink" title="1. 模型"></a>1. 模型</h2><p>我们假设这篇文章的读者对于EM算法有着一定了解。</p>
<h3 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1 原理"></a>1.1 原理</h3><p>在之前的文章<a href="https://protao.github.io/2018/05/27/MachingLearning-2018-05-27-EMAlgorithm/">EM算法原理与推导</a>中我们提到：</p>
<blockquote>
<p>假设我们有数据集\(X={x_{(1)},x_{(2)},…,x_{(m)}}\)，我们想利用生成式模型建模\(P(x;\theta)\)。…… 认为数据来自于多个分布，只不过我们无法观测到数据被哪一个子分布生成，因此不能直接利用公式直接计算解析解。EM算法就是用来处理这种具有“隐标签”的问题的。</p>
</blockquote>
<p>同样，在PRML一书第九章第一句话也给出了提纲挈领的表述：</p>
<blockquote>
<p>如果我们定义观测变量和潜在变量的一个<strong>联合概率分布</strong>，那么对应的观测变量本身的<strong>概率分布</strong>可以通过求<strong>边缘概率</strong>的方法得到。这使得观测变量上的复杂的边缘概率分布可以通过观测变量与潜在变量组成的<strong>扩展空间</strong>上的更加便于计算的联合概率分布来表示。因此，潜在变量的引入使得复杂的概率分布可以由简单的分量组成。</p>
</blockquote>
<p>高斯混合模型就是这种情况的特例。我们以比较简单的语言整理一下这两段话。（不要在意把我自己的文章中的话和机器学习圣经中的话放到一起这件事…）<br>关键是弄明白这三个粗体的“概率”的意思，我们是在为无标签数据建立无监督的生成式模型\(P(x;\theta)\)。在这里，所谓模型，就是概率。$$$ P(x;\theta)=\sum_zP(x^{(i)},z^{(i)};\theta) $$$，就是指“观测变量本身的<strong>概率分布</strong>可以通过求<strong>边缘概率</strong>的方法得到。”，用模型的方式说就是混合模型的就是多个模型的累加和。而边缘概率又是对联合概率中某一随机变量的求和，之所以“定义观测变量和潜在变量的一个<strong>联合概率分布</strong>”，是因为联合概率分布就是子模型，而子模型好求。而单个父模型扩展成多个子模型的原因是，我们增加了一个变量，这个变量是隐变量，从而人为增加了一个变量维度。</p>
        
          <p class="article-more-link">
            <a href="../../2018/05/30/机器学习-2018-05-30-GMM/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/05/30/机器学习-2018-05-30-GMM/" data-id="cjxo5e6st004bz16d5d5ldwg9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/generative/">generative</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/maths/">maths</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/model/">model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/tools/">tools</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-机器学习-2018-05-28-EMAlgorithm2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2018/05/28/机器学习-2018-05-28-EMAlgorithm2/" class="article-date">
  <time datetime="2018-05-27T16:00:00.000Z" itemprop="datePublished">2018-05-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2018/05/28/机器学习-2018-05-28-EMAlgorithm2/">EM算法原理与推导(续)</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="关于更新参数"><a href="#关于更新参数" class="headerlink" title="关于更新参数"></a>关于更新参数</h2><p>关于参数如何更新，其实有多种解释都一样，但是为了理清思路，我们要明确一点就是我们即使不对混合模型的对数似然进行任何变化，也是可以做MLE估计的，只是得到的参数最优值不是一个解析式，而是一个涉及到“隐变量”的式子，这才导致我们后续的EM算法并通过迭代方式来最大化似然。用GMM举例子，我们希望极大化：</p>
<p>$$ l(\theta)=\sum_{i=1}^mlog\sum_zP(x^{(i)},z^{(i)};\theta)\qquad(1)$$<br>$$=\sum_{i=1}^mlog\sum_k\frac{1}{(2\pi)^{n/2}|\Sigma_i|^{1/2}}exp\Big(-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)\Big)*\phi_k \quad(1.1)$$</p>
<p>这个式子计算的是X被生成的概率，而不考虑来自于哪个组分。我们就啥也不考虑，假设求$$$\mu_k$$$的最优值，直接令其梯度为零，就可以得到：</p>
<p>$$ \sum_{i=1}^m \frac{\phi_k\mathcal{N}(x_i|\mu_k,\Sigma_k)}{\sum_j\phi_j\mathcal{N}(x_i|\mu_j,\Sigma_j)}*\Sigma_k^{-1}(x^{(i)}-\mu_k)=0 \qquad(2)$$<br>$$ \mu_k:=\frac{\sum_{i=1}^mP(z^{(i)}=k|x^{(i)};\mu_k,\Sigma_k)x^{(i)}}{\sum_{i=1}^mP(z^{(i)}=k|x^{(i)};\mu_k,\Sigma_k)} \qquad(2.1)$$</p>
<p>注意（2）中的大的分式就是出现在（2.1）中的后验概率。注意在（2.1）的解的形式，是对数据集中所有数据点的加权平均的方式得到参数的解，后验概率作为其中的权重因子。从感性上看，解的形式很好理解，正常单个的高斯分布参数估计就是求数据点的均值来得到高斯分布的均值参数，而GMM就是以“按劳分配“的方式更新。另外其他的参数更新也可以直接通过对（1.1）的MLE得到。<br>不出意外地，每个参数的估计公式中，都有<strong>reponsibility</strong>的参与，而责任作为后验概率，又依赖于参数，这使得我们清晰的得到EM算法迭代的思路。</p>
<h2 id="期望最大化"><a href="#期望最大化" class="headerlink" title="期望最大化"></a>期望最大化</h2><p>既然这个算法叫期望最大化，那么这里就仔细看看期望在哪，怎么最大化的。<br>其实一切都在<a href="https://protao.github.io/2018/05/27/MachingLearning-2018-05-27-EMAlgorithm/#more">上一篇文章</a>的（9）式中了。还是老生常谈的那句话，这几篇文章中寂静说过很多很多次了，<strong>我们算不了复杂的边缘概率，于是妥协为计算联合分布的概率。但是想算联合分布，我们需要知道人为扩展出来的隐变量，但是我们不知道，所幸我们知道隐变量当前状态下的后验概率。那么好，我们就计算联合分布（的对数）的期望。</strong>这个期望，在PRML一书中，用下式表示：</p>
<p>$$ \mathcal{Q}(\theta, \theta^{old})=\sum_ZP(Z|x,\theta^{old})lnP(x,Z|\theta) \qquad(3)$$<br>$$ \mathcal{Q}(\theta, \theta^{old})=\sum_i\sum_ZP(Z|x^{(i)},\theta^{old})lnP(x^{(i)},Z|\theta) \qquad(3.1)$$<br>（3）是单个数据点的形式，容易推导，（3.1）是全部数据的形式，是真正的期望函数。这个就是我们的算法中核心的期望，也是最大化的目标，我们希望给调整$$$\theta$$$，来最大化这个式子，在M步中$$$\theta^{old}$$$是固定的，后验分布也是固定的。（3.1）式其实和<a href="https://protao.github.io/2018/05/27/MachingLearning-2018-05-27-EMAlgorithm/#more">上一篇文章</a>的（9）和（10）式是一致的。log里的形式不太一样，但是不会影响最终的结果。</p>
<h3 id="举例：伯努利混合模型"><a href="#举例：伯努利混合模型" class="headerlink" title="举例：伯努利混合模型"></a>举例：伯努利混合模型</h3><p><em>参考PRML</em></p>
<p>假设数据是D维向量，该数据的每一个维度来自于一个独立的伯努利分布，然后混合模型来自于K个component的线性组合，此时我们有$$$KD$$$个参数，可以认为$$$\mu_{ij}$$$表示第i个多维伯努利组分的第j维的参数。那么显变量的对数似然为：<br>$$ln(X;\mu,\pi)=\sum_{i=1}^mln\Big( \sum_{k=1}^K\pi_k\prod_{d=1}^D\mu_{kd}^{x_{id}}(1-\mu_{kd})^{1-x_{id}} \Big)$$<br>这个无法直接求解，按照上面叙述的，直接写出E步需要求的后验概率和期望：<br>后验概率：<br>$$ \omega_{nk}=P(z_n=k|x_n;\pi,\mu)=\frac{\pi_kP(x_n|\mu_k)}{\sum_j\pi_jP(x_n|\mu_j)} $$<br>联合分布对数似然的期望:<br>$$ \mathbb{E}_Z\big[lnP(X,Z|\mu,\pi)\big]=\sum_i\sum_Z\omega_{nk}\big(ln\pi_k+\sum_{d=1}^D[x_{id}ln\mu_{kd}+(1-x_{id})ln(1-\mu_{kd})]\big) $$<br>然后M步对其最大化。</p>
<h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> logsumexp</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">p=pathlib.Path(<span class="string">"trainingDigits/"</span>)</span><br><span class="line">cache=[]</span><br><span class="line">label=[]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> p.iterdir():</span><br><span class="line">    <span class="keyword">with</span> open(str(fname),<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cache.append(i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines())</span><br><span class="line">        label.append(int(str(fname.name)[<span class="number">0</span>]))</span><br><span class="line">data=np.array([[list(map(int,line)) <span class="keyword">for</span> line <span class="keyword">in</span> digit] <span class="keyword">for</span> digit <span class="keyword">in</span> cache])</span><br><span class="line">label=np.array(label)</span><br><span class="line"></span><br><span class="line">p=pathlib.Path(<span class="string">"testDigits/"</span>)</span><br><span class="line">cache=[]</span><br><span class="line">answer=[]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> p.iterdir():</span><br><span class="line">    <span class="keyword">with</span> open(str(fname),<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cache.append(i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines())</span><br><span class="line">        answer.append(int(str(fname.name)[<span class="number">0</span>]))</span><br><span class="line">test=np.array([[list(map(int,line)) <span class="keyword">for</span> line <span class="keyword">in</span> digit] <span class="keyword">for</span> digit <span class="keyword">in</span> cache])</span><br><span class="line">answer=np.array(answer)</span><br><span class="line"></span><br><span class="line">M = len(data)</span><br><span class="line">D = np.prod(data[<span class="number">0</span>].shape)</span><br><span class="line">K = len(np.unique(label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># initial by label</span></span><br><span class="line">init_mu=[]</span><br><span class="line">init_phi=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">    index=label==i</span><br><span class="line">    labeled_data=data[index].reshape(<span class="number">-1</span>,D)</span><br><span class="line">    init_mu.append(np.sum(labeled_data,axis=<span class="number">0</span>)/len(labeled_data))</span><br><span class="line">    init_phi.append(sum(label==i)/M)</span><br><span class="line"></span><br><span class="line">init_mu=np.array(init_mu)</span><br><span class="line">init_phi=np.array(init_phi)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MixtureBernoulli</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,K,D,M)</span>:</span></span><br><span class="line">        self.K=K <span class="comment"># 组分数</span></span><br><span class="line">        self.D=D <span class="comment"># 数据维度</span></span><br><span class="line">        self.M=M <span class="comment"># 数据规模</span></span><br><span class="line">        self.phi = np.random.ranf((<span class="number">1</span>,K))</span><br><span class="line">        self.phi /= sum(self.phi)</span><br><span class="line">        self.mu = np.random.ranf((K,D))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setPara</span><span class="params">(self, phi=None, mu=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> phi <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">	        self.phi = phi</span><br><span class="line">        <span class="keyword">if</span> mu <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        	self.mu = mu</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_log_bernoulli</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        np.clip(self.mu, <span class="number">1e-10</span>, <span class="number">1</span><span class="number">-1e-10</span>, out=self.mu)</span><br><span class="line">        <span class="keyword">return</span> (X[:,<span class="keyword">None</span>,:]*np.log(self.mu)+(<span class="number">1</span>-X[:,<span class="keyword">None</span>,:])*np.log(<span class="number">1</span>-self.mu)).sum(axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_E_Step</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        responsibility=np.log(self.phi)+self._log_bernoulli(X)</span><br><span class="line">        responsibility -= logsumexp(responsibility, axis=<span class="number">1</span>).reshape((X.shape[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> np.exp(responsibility)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_M_Step</span><span class="params">(self, X, responsibility)</span>:</span></span><br><span class="line">        <span class="comment"># Nk是所有数据点在第k个组分的权重和，所以sum(Nk)=M</span></span><br><span class="line">        Nk = np.sum(responsibility,axis=<span class="number">0</span>).reshape((<span class="number">1</span>,self.K))</span><br><span class="line">        self.mu = ((X.T @ responsibility)/Nk).T</span><br><span class="line">        self.phi=Nk/self.M</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self,X,verbose=False)</span>:</span></span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            old_params = np.hstack((self.phi.ravel(), self.mu.ravel()))</span><br><span class="line">            resp = self._E_Step(X)</span><br><span class="line">            self._M_Step(X, resp)</span><br><span class="line">            <span class="keyword">if</span> np.allclose(old_params, np.hstack((self.phi.ravel(), self.mu.ravel()))):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                print(<span class="string">"iteration &#123;&#125;"</span>.format(i))</span><br><span class="line">                <span class="keyword">if</span> verbose:</span><br><span class="line">                    pred=np.argmax(resp,axis=<span class="number">1</span>)</span><br><span class="line">                    print(pred[:<span class="number">1600</span>].reshape(<span class="number">400</span>,<span class="number">-1</span>)[:,<span class="number">0</span>].reshape((<span class="number">20</span>,<span class="number">20</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify_proba</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        posterior probability of cluster</span></span><br><span class="line"><span class="string">        p(z|x,theta)</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : (sample_size, ndim) ndarray</span></span><br><span class="line"><span class="string">            input</span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        output : (sample_size, n_components) ndarray</span></span><br><span class="line"><span class="string">            posterior probability of cluster</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self._E_Step(X)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        classify input</span></span><br><span class="line"><span class="string">        max_z p(z|x, theta)</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : (sample_size, ndim) ndarray</span></span><br><span class="line"><span class="string">            input</span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        output : (sample_size,) ndarray</span></span><br><span class="line"><span class="string">            corresponding cluster index</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> np.argmax(self.classify_proba(X), axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">mb = MixtureBernoulli(K,D,M)</span><br><span class="line">mb.setPara(phi=init_phi, mu=init_mu)</span><br><span class="line">mb.fit(data.reshape(<span class="number">-1</span>, D),verbose=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">pred=mb.classify(test.reshape(test.shape[<span class="number">0</span>],<span class="number">32</span>*<span class="number">32</span>))</span><br><span class="line">confusion_matrix(pred, answer)</span><br><span class="line"></span><br><span class="line">mu0=mb.mu[<span class="number">0</span>].reshape((<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">plt.imshow(mu0, cmap=<span class="string">"gray"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>最后的分类正确率是87%左右。</p>
<p>还是别人家的代码好啊。注意<code>logsumexp</code>这个函数，我就知道有，但是没找到！然后为了防止下溢出用了对数计算，还有<code>np.clip</code>辅助。多分类问题使用<code>sklearn.metric</code>中的混淆矩阵函数进行直观评估。还有自带的<code>pathlib</code>是好帮手。</p>
<h2 id="EM算法与KL散度"><a href="#EM算法与KL散度" class="headerlink" title="EM算法与KL散度"></a>EM算法与KL散度</h2><p>限制考虑单个数据的情况，因为是对数似然，全部数据集只需要求和。<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4)$$<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(z^{(i)}|x^{(i)};\theta)P(x^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4.1)$$<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})lnP(x^{(i)};\theta)+\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(z^{(i)}|x^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4.2)$$<br>$$J(Q,\theta)=lnP(x^{(i)};\theta)-KL(Q||P) \qquad(4.3)$$<br>$$lnP(x^{(i)};\theta)=J(Q,\theta)+KL(Q||P) \qquad(4.4)$$</p>
<p>KL散度这里不展开说，只需要知道：KL散度衡量两个分布的距离，P是被衡量的分布，Q是用来拟合的分布，当两个分布一样的时候，KL散度为零。<br>（4.4）式的意义在于，将真正的对数似然拆分成了两部分，第一部分是我们固定$$$\theta$$$构建的下界，第二部分是在$$$\theta$$$处，下界和真正似然的差距。KL距离是一定大于零的，<strong>在给定$$$\theta$$$时</strong>，对数似然可以想（4.4）一样拆成两部分，我们希望下界$$$J$$$尽可能的大，以使得得到最紧的下界，即KL距离尽可能的小，所以必须要让Q分布等于$$$P(z|x;\theta)$$$，于是得到了和第一篇文章中使用Jensen不等式殊途同归的结果。</p>
<p><img src="/img/EM2.png" alt="图1：在$$$\theta$$$上优化对数似然"><br><img src="/img/EM3.png" alt="图2：固定$$$\theta$$$看（4.4）式"></p>
<p>图2的左图表示图1中$$$\theta_{old}$$$经过E步之后，（4.4）式中三个部分的各个状态：在$$$\theta_{old}$$$处，下界紧贴目标函数且KL距离为0的状态。图2的右图表示图1中$$$\theta_{new}$$$的经过M步的状态，即对下界进行优化，得到新的参数估计。此时在图一中花了三条横线，分别对应图2右图中的三条线，<strong>紫色线表示本次E步之前的对数似然，然后从$$$\theta_{old}$$$变成$$$\theta_{new}$$$后，$$$J(Q,\theta)$$$提升到了蓝线的高度，$$$lnP(x^{(i)};\theta)$$$提升到了红线的高度，$$$KL(Q||P)$$$从0变成了蓝红两线的间距</strong>，然后本次的M又会把这个间距缩小成0，以此类推。</p>
<p>参考：</p>
<ol>
<li><a href="https://www.zhihu.com/question/27976634?sort=created" target="_blank" rel="noopener">怎么通俗易懂地解释EM算法并且举个例子?</a></li>
<li><a href="http://www.elecfans.com/d/604076.html" target="_blank" rel="noopener">关于EM算法的九层境界的浅薄介绍，Hinton和Jordan理解的EM算法</a></li>
<li><a href="https://spaces.ac.cn/archives/5239" target="_blank" rel="noopener">从最大似然到EM算法：一致的理解方式</a></li>
<li><a href="https://spaces.ac.cn/archives/4277" target="_blank" rel="noopener">梯度下降和EM算法：系出同源，一脉相承</a></li>
<li>Patttern Recognition and Machine Learning 中译版</li>
<li><a href="https://github.com/ctgk/PRML/blob/master/prml/rv/bernoulli_mixture.py" target="_blank" rel="noopener">PRML读书伴侣ch9</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/05/28/机器学习-2018-05-28-EMAlgorithm2/" data-id="cjxo5e6su004cz16dm770bgn4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/generative/">generative</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/maths/">maths</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/tools/">tools</a></li></ul>

    </footer>
  </div>
  
</article>





  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="../14/">&laquo; 上一页</a><a class="page-number" href="../../">1</a><span class="space">&hellip;</span><a class="page-number" href="../13/">13</a><a class="page-number" href="../14/">14</a><span class="page-number current">15</span><a class="page-number" href="../16/">16</a><a class="page-number" href="../17/">17</a><span class="space">&hellip;</span><a class="page-number" href="../28/">28</a><a class="extend next" rel="next" href="../16/">下一页 &raquo;</a>
  </nav>


<!-- 文章目录 --> 


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../categories/C/">C++</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/python/">python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/信息安全/">信息安全</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/大数据/">大数据</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/数学/">数学</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/机器学习/">机器学习</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/生活/">生活</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/程序员的玩具/">程序员的玩具</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/读书笔记/">读书笔记</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="../../tags/C/">C++</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/algorithm/">algorithm</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/bigdata/">bigdata</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/database/">database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/dataprocessing/">dataprocessing</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/deeplearning/">deeplearning</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/financing/">financing</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/generative/">generative</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hadoop/">hadoop</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hash/">hash</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hbase/">hbase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/linux/">linux</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/machinelearning/">machinelearning</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/maths/">maths</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/model/">model</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/mysql/">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/nlp/">nlp</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/numpy/">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/python/">python</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/reading/">reading</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/scala/">scala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/security/">security</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/shell/">shell</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/spark/">spark</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/spider/">spider</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/tools/">tools</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/translation/">translation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/trick/">trick</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/web/">web</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="../../tags/C/" style="font-size: 17.69px;">C++</a> <a href="../../tags/algorithm/" style="font-size: 19.23px;">algorithm</a> <a href="../../tags/bigdata/" style="font-size: 15.38px;">bigdata</a> <a href="../../tags/database/" style="font-size: 10px;">database</a> <a href="../../tags/dataprocessing/" style="font-size: 12.31px;">dataprocessing</a> <a href="../../tags/deeplearning/" style="font-size: 13.85px;">deeplearning</a> <a href="../../tags/financing/" style="font-size: 11.54px;">financing</a> <a href="../../tags/generative/" style="font-size: 12.31px;">generative</a> <a href="../../tags/hadoop/" style="font-size: 12.31px;">hadoop</a> <a href="../../tags/hash/" style="font-size: 12.31px;">hash</a> <a href="../../tags/hbase/" style="font-size: 10px;">hbase</a> <a href="../../tags/linux/" style="font-size: 13.85px;">linux</a> <a href="../../tags/machinelearning/" style="font-size: 16.92px;">machinelearning</a> <a href="../../tags/maths/" style="font-size: 16.15px;">maths</a> <a href="../../tags/model/" style="font-size: 11.54px;">model</a> <a href="../../tags/mysql/" style="font-size: 10px;">mysql</a> <a href="../../tags/nlp/" style="font-size: 14.62px;">nlp</a> <a href="../../tags/numpy/" style="font-size: 10px;">numpy</a> <a href="../../tags/python/" style="font-size: 18.46px;">python</a> <a href="../../tags/reading/" style="font-size: 20px;">reading</a> <a href="../../tags/scala/" style="font-size: 10px;">scala</a> <a href="../../tags/security/" style="font-size: 13.85px;">security</a> <a href="../../tags/shell/" style="font-size: 13.08px;">shell</a> <a href="../../tags/spark/" style="font-size: 10.77px;">spark</a> <a href="../../tags/spider/" style="font-size: 10px;">spider</a> <a href="../../tags/tools/" style="font-size: 17.69px;">tools</a> <a href="../../tags/translation/" style="font-size: 10.77px;">translation</a> <a href="../../tags/trick/" style="font-size: 12.31px;">trick</a> <a href="../../tags/web/" style="font-size: 11.54px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/06/">六月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/05/">五月 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/04/">四月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/03/">三月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/02/">二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/11/">十一月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/10/">十月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/07/">七月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/06/">六月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/04/">四月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/03/">三月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/09/">九月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/08/">八月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/07/">七月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/06/">六月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../../2019/06/17/生活-2019-06-17-GTD/">《搞定I——无压工作的艺术》</a>
          </li>
        
          <li>
            <a href="../../2019/05/26/C-2019-05-26-Effective-CPP-IV/">《Effective C++》第四部分：设计和声明</a>
          </li>
        
          <li>
            <a href="../../2019/05/17/C-2019-05-17-Effective-CPP-III/">《Effective C++》第三部分：资源管理</a>
          </li>
        
          <li>
            <a href="../../2019/05/10/机器学习-2019-05-10-alchemy-trick/">仓鼠一般搜集到的炼丹技巧</a>
          </li>
        
          <li>
            <a href="../../2019/05/08/Python-2019-05-08-SICP2/">Python中使用函数构建对象</a>
          </li>
        
      </ul>
    </div>
  </div>

  


  </span>
</aside>

        
      </div>
      <footer id="footer">

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Yongtao Zhang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="../../index.html" class="mobile-nav-link">home</a>
  
    <a href="../../archives" class="mobile-nav-link">archives</a>
  
    <a href="../../about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="../../fancybox/jquery.fancybox.css">
  <script src="../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../js/script.js"></script>



  </div>
</body>
</html>