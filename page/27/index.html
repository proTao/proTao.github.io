<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>proTao的大脑具现</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="proTao的大脑具现">
<meta property="og:url" content="https://protao.github.io/page/27/index.html">
<meta property="og:site_name" content="proTao的大脑具现">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="proTao的大脑具现">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="../../css/style.css">
  <meta name="baidu-site-verification" content="xerEdoxBbf">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)'],['$$$','$$$'],['$','$']]}
});
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../index.html" id="logo">proTao的大脑具现</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../index.html">home</a>
        
          <a class="main-nav-link" href="../../archives">archives</a>
        
          <a class="main-nav-link" href="../../about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://protao.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    

<article id="post-机器学习-2017-05-18-ComputerVisionGMM" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2017/05/18/机器学习-2017-05-18-ComputerVisionGMM/" class="article-date">
  <time datetime="2017-05-17T16:00:00.000Z" itemprop="datePublished">2017-05-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2017/05/18/机器学习-2017-05-18-ComputerVisionGMM/">使用混合高斯模型对背景建模</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、原理"><a href="#一、原理" class="headerlink" title="一、原理"></a>一、原理</h2><p>用GMM对背景建模的基本思想是把每一个像素点所呈现的颜色用K个高斯分布的叠加来表示，通常K取3-5之间。将像素点所呈现的颜色X认为是随机变量，则在每时刻t=1,…,T所得到视频帧图像的像素值只是随机变量X的采样值（观值）。</p>
<p>在进行前景检测前，先对背景进行训练，对每一帧图像中每个背景采用一个混合高斯模型进行模拟，背景一旦提取出来，前景的检测就简单了，检查像素是否与背景的高斯模型匹配，匹配是背景，不匹配就是前景。</p>
<p>所以关键就是混合高斯背景模型的建立。</p>
<p>GMM之所以能够将前景和背景分开是基于如下两点事实的：</p>
<p>(1)在长期观测的场景中，背景占大多数时间，更多的数据是支持背景分布的</p>
<p>(2)即使是相对颜色一致的运动物体也会比背景产生更多变化，况且一般情况下物体都是带有不同颜色的。</p>
<h2 id="二、算法流程"><a href="#二、算法流程" class="headerlink" title="二、算法流程"></a>二、算法流程</h2><ol>
<li>参数初始化：定义对每个像素建立几个单高斯组成混合高斯模型，一般去3到5，我取4，变量定义为C=4。另外每个高斯分布需要用三个变量表示，分别是权重w，均值mean和方差pixel_sd。对图像的每个像素都需要建立C个高斯分布，所以这三个高斯分布参数变量是三个height*width*C大小的三维矩阵。初始化时，令mean在像素取值范围内去随机数，w取1/C，pixel_sd人工进行初始化，我取值为9。另外几个参数后面提到再详细说明。</li>
<li>一次读取一幅图像（假设像素是单通道，多通道的图像分别计算），对每个像素计算与本像素各个高斯的均值的差的绝对值，然后计算这个差值是否小于对应高斯的方差的D倍，这个是为了容忍噪音的，否则当北京训练趋于稳定的时候，方差会很小，很容易就与当前高斯模型不匹配。D通常定义为2.5。对于匹配的高斯模型参数进行如下调整（其中p是alpha/w，alpha是人为定义的学习速率，用于更新权重，p用于更新高斯模型，除以w的作用是使得权重越大的模型越稳定，而权重过小的新定义的模型可以更快的收敛）：<br><img src="/img/ComputerVisionGMM1.png" alt></li>
</ol>
<p>对于所有的高斯模型的权重进行如下更新：<br><img src="/img/ComputerVisionGMM2.png" alt></p>
<p>另一种参考文章里的更好的更新方式：<br><img src="/img/ComputerVisionGMM2.1.png" alt></p>
<p>M是match的意思，也就是说如果当前像素与对应高斯匹配，M=1，否则M=0。</p>
<ol start="3">
<li>我们发现进行上述更新后，匹配到的高斯权重会变大，没有被匹配的高斯权重会变变小，所以更新完成后，权重值和可能不唯一，所以要进行权重的归一化。</li>
<li>然后对每个像素的所有高斯进行rank的计算，rank=w/pixel_sd，也就是说rank分高意味着权重大、方差小。如果某个像素点的所有高斯都没有被匹配，就说明那个像素的模型建立得不好，就把rank最小的高斯模型换成一个匹配当前像素值的高斯，即mean设为当前高斯像素值，方差用人工定义的值初始化，w不变。</li>
<li>然后进行北京的选择，这里需要定义一个阈值thresh，表示所有高斯模型中有多少比例构成北京，按照rank顺序将w进行累加，知道前B个高斯的权重满足thresh，就完成北京的选择。</li>
</ol>
<h2 id="三、实验"><a href="#三、实验" class="headerlink" title="三、实验"></a>三、实验</h2><p>代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">close all</span><br><span class="line">clc</span><br><span class="line">% ----------------------- 使用第一帧获取图片大小 -----------------------</span><br><span class="line"></span><br><span class="line">addpath(<span class="string">'./data'</span>);</span><br><span class="line">img_dir = dir(<span class="string">'./data/*.jpg'</span>);</span><br><span class="line">fr = imread(img_dir(1).name);           % 读第一幅图片</span><br><span class="line">[height,width] = size(fr(:,:,3)); </span><br><span class="line"></span><br><span class="line">% ----------------------- 变量初始化 -----------------------------------</span><br><span class="line"></span><br><span class="line">tolerance = 1;</span><br><span class="line">C_max = 4;                       % 组成混合高斯模型的最多单高斯数目</span><br><span class="line">D = 2.5;                     % 阀值（一般为2.5个标准差）</span><br><span class="line">alpha = 0.01;               % 学习速率（一般为0到1）</span><br><span class="line">thresh = 0.6;               % 前景阀值（0.25到0.47）</span><br><span class="line">sd_init = 9;                 % 初始化标准差</span><br><span class="line"></span><br><span class="line">% -------------------------初始化均值,权值和方差----------------------------</span><br><span class="line"> </span><br><span class="line">pixel_depth = 8;                        %  像素深度为8位</span><br><span class="line">pixel_range = 2^pixel_depth - 1;         %  灰度范围</span><br><span class="line"></span><br><span class="line">w=ones(height, width, C_max)/C_max;</span><br><span class="line">pixel_sd=ones(height, width, C_max)*sd_init;</span><br><span class="line">mean=rand(height, width, C_max)*pixel_range;</span><br><span class="line"><span class="built_in">bg</span>=zeros(height, width,3);</span><br><span class="line">% -------------------------用于调试-------------------------</span><br><span class="line">mean_history=zeros(C_max, 200);</span><br><span class="line">pixel_sd_history=zeros(C_max, 200);</span><br><span class="line">w_history=zeros(C_max, 200);</span><br><span class="line">sort_history = zeros(C_max, 200);</span><br><span class="line">match_history = zeros(C_max, 200);</span><br><span class="line">%--------------------- 处理每一帧 -----------------------------------</span><br><span class="line"><span class="keyword">for</span> c =1:3</span><br><span class="line">    <span class="keyword">for</span> n = 1:150,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        % ----------------- diff ------------------</span><br><span class="line">        fr = imread(img_dir(n).name);       </span><br><span class="line"></span><br><span class="line">        % 把图像赋值C_max层，便于后面的矢量化操作</span><br><span class="line">        pixel=zeros(height,width,C_max);</span><br><span class="line">        <span class="keyword">for</span> i = 1:C_max</span><br><span class="line">            pixel(:,:,i) = fr(:,:,c);</span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        % 计算像素差的绝对值</span><br><span class="line">        u_diff = abs(double(pixel) - double(mean));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        % 获得针对每个像素各个高斯分布的c_max层的match矩阵，为1的元素是匹配到的高斯成分</span><br><span class="line">        match = (u_diff &lt;= (D*pixel_sd+tolerance)) ;</span><br><span class="line">        <span class="keyword">for</span> i = 1:C_max</span><br><span class="line">            match_history(i,n) = sum(sum(match(:,:,i)))/(576*720);</span><br><span class="line">        end</span><br><span class="line">        % 根据match更新各个高斯分布参数</span><br><span class="line">        p = ones(height,width,C_max)*alpha./w;</span><br><span class="line">        w = w*(1-alpha)+match*alpha;</span><br><span class="line">        delta = pixel.*match + (1-match).*mean;</span><br><span class="line">        mean = (1-p).*mean + p.*delta;</span><br><span class="line">        delta = sqrt((1-p).*pixel_sd.^2 + p.*(double(pixel) - mean).^2);</span><br><span class="line">        pixel_sd = match.*delta +(1-match).*pixel_sd;</span><br><span class="line"></span><br><span class="line">        % 获得针对每个像素各个高斯分布的c_max层的match矩阵</span><br><span class="line">        % 为1的元素是说明对应位置的像素没有任何一个高斯成分被匹配到，需要把评分最小的高斯成分进行替换</span><br><span class="line">        unmatch=sum(match,3)==0;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        % 计算排序的rank矩阵</span><br><span class="line">        rank=w./pixel_sd;</span><br><span class="line">        [min_rank,min_rank_index] = min(rank,[],3);</span><br><span class="line"></span><br><span class="line">        % 根据min_rank_index生成与w和pixel_sd大小一致的索引old_index，索引矩阵素为1的位置是需要被替换掉的高斯分量</span><br><span class="line">        old_index=ones(height,width,C_max);</span><br><span class="line">        <span class="keyword">for</span> i =1:C_max</span><br><span class="line">            old_index(:,:,i) = ((old_index(:,:,i)*i).*unmatch) == min_rank_index;   </span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        % 对需要替换的高斯分量进行替换</span><br><span class="line">        mean = (1-old_index).*mean + old_index.*double(pixel);</span><br><span class="line">        pixel_sd=(1-old_index).*pixel_sd + old_index.*(ones(height,width,C_max)*sd_init);</span><br><span class="line"></span><br><span class="line">        % 权值归一化   </span><br><span class="line">        sum_w=sum(w,3);</span><br><span class="line">        <span class="keyword">for</span> i=1:C_max</span><br><span class="line">            w(:,:,i) = w(:,:,i)./sum_w;</span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        rank=real(w./pixel_sd);    % 不知道为什么算出来时虚数，但是虚部为零，用real处理一下</span><br><span class="line">        [sort_rank, sort_rank_index] = sort(rank, 3, <span class="string">'descend'</span>);</span><br><span class="line">        background = zeros(height,width);</span><br><span class="line">        now_thresh = zeros(height,width);</span><br><span class="line">        bg_match = zeros(height,width,C_max);</span><br><span class="line">        <span class="keyword">for</span> i = 1:C_max</span><br><span class="line">            [x,y]=meshgrid(1:width,1:height);</span><br><span class="line">            now_index = (sort_rank_index(:,:,i)-1)*height*width+(x-1)*height+y;</span><br><span class="line">            bg_match(:,:,i) = now_thresh&lt;=thresh;</span><br><span class="line">            now_thresh = now_thresh + w(now_index);</span><br><span class="line">            background = background + mean(now_index).*w(now_index).*bg_match(:,:,i);</span><br><span class="line">            sort_history(i,n) = sum(sum(sort_rank_index(:,:,i)));</span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        bg_match = (1-match).*(1-bg_match);</span><br><span class="line">        bg_match = sum(bg_match,3)&gt;0;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        % -------------统计---------------</span><br><span class="line">        <span class="keyword">for</span> i = 1:C_max</span><br><span class="line">            w_history(i,n) = sum(sum(w(:,:,i)))/(576*720);</span><br><span class="line">            mean_history(i,n) = sum(sum(mean(:,:,i)))/(576*720);</span><br><span class="line">            pixel_sd_history(i,n) = sum(sum(pixel_sd(:,:,i)))/(576*720);</span><br><span class="line"></span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        imshow(uint8(background))</span><br><span class="line">        drawnow</span><br><span class="line">        n</span><br><span class="line"></span><br><span class="line">    end</span><br><span class="line">    <span class="built_in">bg</span>(:,:,c)=background;</span><br><span class="line">end</span><br><span class="line">imwrite(uint8(<span class="built_in">bg</span>),<span class="string">'bg2.jpg'</span>)</span><br></pre></td></tr></table></figure>
<p>视频截图：<br><img src="/img/ComputerVisionGMM5.jpg" alt></p>
<p>选择150张图片进行背景建模，分通道提取单色背景，然后将三个颜色进行叠加，背景如下：<br><img src="/img/ComputerVisionGMM3.png" alt></p>
<h2 id="四、调参"><a href="#四、调参" class="headerlink" title="四、调参"></a>四、调参</h2><ol>
<li>矢量化编程</li>
</ol>
<p>开始的时候使用for循环对每张图片每个像素进行上述计算，在matlab上一次处理200张图片需要2个小时左右，这使得尝试新参数变得很困难，因为一个下午满打满算也只能尝试两三组参数。</p>
<p>后来在深度学习相关资料上看到了矢量化编程的概念，就是在python或者matlab等类似较高层语言上进行数学计算的时候，尽量不要使用for循环，要利用内建的适量运算来达到并行，然后按照矢量化的方法进行重写之后，一次运行需要5到10分钟左右。</p>
<p>具体方法是一幅图像看成一个height*width*C_max的图像，然后直接对这个三维数组进行运算，如果涉及到匹配与不匹配的运算不同的情况，添加一个同样大小的match数组来表明当前位时候需要计算。</p>
<ol start="2">
<li>关于调参<br><img src="/img/ComputerVisionGMM4.png" alt="第一个高斯的命中率"></li>
</ol>
<p>  如上图示第一个高斯配匹配的命中率，其他几个高斯分布大致如此不过第一个的命中率最高。关于阈值，基本上最大的高斯分布的阈值在0.3-0.5左右，如果阈值过小，会只取到一个高斯，阈值过大又会取到不属于背景的部分。最后经过尝试thresh=0.6</p>
<p>参考：<a href="https://www.cnblogs.com/tornadomeet/archive/2012/06/02/2531565.html" target="_blank" rel="noopener">前景检测算法GMM</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/05/18/机器学习-2017-05-18-ComputerVisionGMM/" data-id="cjxo5e6rt0040z16dkjx58he6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-数学-2017-5-15-GridPath" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2017/05/15/数学-2017-5-15-GridPath/" class="article-date">
  <time datetime="2017-05-14T16:00:00.000Z" itemprop="datePublished">2017-05-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/数学/">数学</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2017/05/15/数学-2017-5-15-GridPath/">组合数学之方格路径</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一个简单的问题"><a href="#一个简单的问题" class="headerlink" title="一个简单的问题"></a>一个简单的问题</h1><p>问从一个横边长为m，竖边长为n方格棋盘的一个角走到对角点的最短路径共有多少种方法？这个问题应该会有很多人见到过，想明白的话这也是一个很简单的问题，但是如果在这个问题上进行一点小小的改变，这个问题也是可以很有意思的。<br><img src="http://img.blog.csdn.net/20170421180852325?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h1 id="level-0"><a href="#level-0" class="headerlink" title="level 0"></a>level 0</h1><p>方便起见就不失一般性的假设棋盘大小是4*3：<br><img src="http://img.blog.csdn.net/20170421181801397?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>那么问题就是从左下角到右上角的路经数目有多少？<br>一种思路就是用动态规划的思想，到格子（i，j）处的只有两种方法：从（i-1，j）向右走一步或者从（i，j-1）处向上走一步。用N（i，j）表示从起点到（i，j）的路径数，则：</p>
<blockquote>
<p>N（i，j）=N（i-1，j）+N（i，j-1）</p>
</blockquote>
<p>所以这个3*4的棋盘问题可解：<br><img src="http://img.blog.csdn.net/20170421212148349?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="动态规划解法"><br>但是说的高大上是动态规划算法，说的不好听了不就是傻算嘛……换一个角度考虑就能转化成一个高中就能瞬间写出答案的问题，其实就是一种选择的问题。因为在每个路口都要做出选择，是向上还是向右走。就好像我高中骑车上学一样。假设我家在左下角（0，0），学校在右上角（4，3）。那么我可以先向右骑一段路，到路口（1，0），我可以选择向东直行到（2，0）或者左拐到（1， 1）处，每一个路口都要做出选择，但是全程我必须也只能向北走三段路，同理向东走四段路，即在全程长为7的路程中选择三段路向北走，四段路向东走。<br>例如（U U R U R R R ）或者（R U R U R U R）或者（R R R R U U U）都是可能的路径。（U表示向上走，R表示向右走）。<br>所以总路程数就是：</p>
<blockquote>
<p>C(7,3) = C(7,4) = 35</p>
</blockquote>
<p>同理从（0，0）点走到（m，n）处的路线数就是C（m+n，n）或者C（m+n，m）。</p>
<h1 id="level-1"><a href="#level-1" class="headerlink" title="level 1"></a>level 1</h1><p>好！小棋盘升级了！现在我们的问题改变了，在一个m<em>m正方形棋盘上从角点（0，0）走到对角线上的最短路线有多少种？<br><img src="http://img.blog.csdn.net/20170421230132820?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>升了一级也没感觉怎么样嘛！每一个路口有2种向上向右两种走法，走m步，共$2^m$种路线。就拿这个9</em>9的图来说，答案就是$2^9$呗！so easy！我想说的是，除了这一个思路，用level 0的想法解这道题。<br>从上往下，到达第一个点的路径数目是C（9，0），到达第二个点的路径数目是C（9，1），依次类推，到达第i个点的路径数目是C（9，i-1），这里 i 的取值区间是大于等于0，小于等于9。也就是说，总共的路径数是：</p>
<blockquote>
<p>$\sum_{i=0}^9C(9,i)$</p>
</blockquote>
<p>这十个值分别是1,9,36,84,126,126,84,36,9,1，而如果把这个计算过程写下来的话，我们会发现这不就是杨辉三角嘛！<br><img src="http://img.blog.csdn.net/20170422011612519?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>                        —（图片来自百度，侵删）—<br>
        
          <p class="article-more-link">
            <a href="../../2017/05/15/数学-2017-5-15-GridPath/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/05/15/数学-2017-5-15-GridPath/" data-id="cjxo5e6rr003zz16diuybq8pu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/maths/">maths</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-机器学习-2017-4-12-BaumWalch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2017/04/12/机器学习-2017-4-12-BaumWalch/" class="article-date">
  <time datetime="2017-04-11T16:00:00.000Z" itemprop="datePublished">2017-04-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2017/04/12/机器学习-2017-4-12-BaumWalch/">HMM模型之三——Baum-Walch算法</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="参数问题"><a href="#参数问题" class="headerlink" title="参数问题"></a>参数问题</h1><p>（自己挖的坑，跪着也要写完！(╯‵□′)╯︵┻━┻）</p>
<h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><p>前面说了HMM的解码和评估，但是这都是建立在我们有了HMM的正确参数的前提条件下。然而如果我们真的想解决实际问题，比如动作识别，语音识别等问题时，很难有最优的参数用来预设值。如果我们有先验知识，可以在初始化的时候使参数向最优值靠近一些，如果没有的时候，甚至我们只能用将概率1均分来赋初值。那么这种时候怎么办，连模型参数都没有，怎么评估，怎么解码？</p>
<p>在第一篇文章中，讲前向算法的地方，我们假设，我们统计了一学期的食堂后厨的轮班记录，也就是说我们有一个小间谍，使得我可以掌握隐藏状态的序列，那么整个模型的状态图就是完全可见的了，只要数据够多，我只需要用最大似然估计去统计频率就可以去无限的逼近真实参数了。</p>
<p>现在问题就是我们无法拿到内部状态序列的数据，无法求HMM的参数Pi，A，B，也就无法进行前向变量、后向变量和维特比算法的计算。这个问题看似无法解决，但是Baum大神还是找到了一个解决这个问题的方法，这类算法都属于一类叫做EM算法的范畴。<br>我对这类算法的浅显的理解是，在数据量足够的情况下通过一次次的递归来笔记呢模型中的特定隐含参数的真实值。首先随意对内部参数赋值，然后得到一种解释输出的分布，然后对新得到的分布求内部参数的期望，得到新的内部参数值，在重新对可能的分布进行估值，以此类推。我的解释可能不到位，引用<a href="http://www.52nlp.cn/hmm-learn-best-practices-seven-forward-backward-algorithm-3" target="_blank" rel="noopener">HMM学习最佳范例中七</a>中的解释：</p>
<blockquote>
<p>直观地理解EM算法，它也可被看作为一个逐次逼近算法：事先并不知道模型的参数，可以随机的选择一套参数或者事先粗略地给定某个初始参数λ0 ，确定出对应于这组参数的最可能的状态，计算每个训练样本的可能结果的概率，在当前的状态下再由样本对参数修正，重新估计参数λ ，并在新的参数下重新确定模型的状态，这样，通过多次的迭代，循环直至某个收敛条件满足为止，就可以使得模型的参数逐渐逼近真实参数。</p>
</blockquote>
<p>对EM算法的一个简单实现是聚类算法中的K-means算法，实现起来比较简单，可以直观的理解算法背后的EM思想。</p>
<p>那么在Baum-Walch算法中怎么实现了EM思想求内部参数呢，这个算法中定义了两个关键变量，是这个算法的重中之重，符号是\(\xi\)和\(\gamma\)，我在后面就称之为gamma变量和xi变量。</p>
<p>首先解释gamma变量，它的计算方法是：</p>
<p><img src="http://img.blog.csdn.net/20170419115429678?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>用图来表示就是这个意思：</p>
<p><img src="http://img.blog.csdn.net/20170419115512191?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>在前面说过，前向变量表示的是在t时刻以状态Si结束时总的概率（给定观测序列\(O_{1…t}\)），也就是计算的是图中的红色框部分。后向变量的意思就是假定时间t时的内部状态是Si，模型输出\(O_{t+1…T}\)的概率，也就是计算上图中的蓝色圆圈中的部分。那么在此基础上，gamma变量的分子的意思就好理解了，它表示的是，在输出完整的观测序列\(O_{1…T}\)的条件下，t时刻的内部状态是Si的概率。而分母就是在输出完整的观测序列的情况下，所有可能的内部状态的和，也就是我们在第一篇文章中说的，整个序列的概率。所以gamma变量的意义就是t时刻出现内部状态Si的概率，这个概率在t时刻是归一的，就是说t时刻的所有gamma变量相加为一。</p>
<p>然后xi变量比gamma变量稍微复杂一点，但是基本思想是一样的，表示的是：由t时刻到t+1时刻出现内部状态Si到Sj的这种转移的概率，公式如下：<br>
        
          <p class="article-more-link">
            <a href="../../2017/04/12/机器学习-2017-4-12-BaumWalch/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/04/12/机器学习-2017-4-12-BaumWalch/" data-id="cjxo5e6s20044z16dnp68gadd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/nlp/">nlp</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-机器学习-2017-3-29-ViterbiAlgorithm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2017/03/29/机器学习-2017-3-29-ViterbiAlgorithm/" class="article-date">
  <time datetime="2017-03-28T16:00:00.000Z" itemprop="datePublished">2017-03-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2017/03/29/机器学习-2017-3-29-ViterbiAlgorithm/">HMM模型之二————Viterbi算法</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="第二个问题：Viterbi算法"><a href="#第二个问题：Viterbi算法" class="headerlink" title="第二个问题：Viterbi算法"></a>第二个问题：Viterbi算法</h2><h3 id="土方法"><a href="#土方法" class="headerlink" title="土方法"></a>土方法</h3><p>现在来到了第二个问题，我吃了三天食堂都是红烧肉，我想知道这三天的大厨最有可能是谁，怎么办？直观的思路还是使用枚举法（没办法啊。。。我总是想出这么简单naive的小白算法）。但是前面已经讨论，这种算法无论是从效率上还是逼格上都太低，因此我们考虑其他的方法。</p>
<h3 id="还算好但是不常用的方法"><a href="#还算好但是不常用的方法" class="headerlink" title="还算好但是不常用的方法"></a>还算好但是不常用的方法</h3><p>我们上一篇文章提到了我们可以用前向变量和后向变量搭配使用求解t时刻内部变量是\(S_i\)且输出观测序列O的概率，那么算出t时刻全部的内部状态的各自的概率，那么概率最大的那个就是t时刻最有可能的内部状态，对每个时刻都进行这样的计算不就可以得到最有可能的内部序列的吗？还是上次我们提到的例子，我吃到了三天红烧肉，想求出隐藏的后厨序列，下面已经给出计算好的前向变量和后向变量。</p>
<table>
<thead>
<tr>
<th>前向变量</th>
<th>t=1</th>
<th>t=2</th>
<th>t=3</th>
</tr>
</thead>
<tbody>
<tr>
<td>大爷(i=1)</td>
<td>0.54</td>
<td>0.0018</td>
<td>0.00549</td>
</tr>
<tr>
<td>大叔(i=2)</td>
<td>0.03</td>
<td>0.0552</td>
<td>0.011142</td>
</tr>
<tr>
<td>大哥(i=3)</td>
<td>0</td>
<td>0.0393</td>
<td>0.004701</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>后向变量</th>
<th>t=1</th>
<th>t=2</th>
<th>t=3</th>
</tr>
</thead>
<tbody>
<tr>
<td>大爷(i=1)</td>
<td>0.368</td>
<td>0.16</td>
<td>1</td>
</tr>
<tr>
<td>大叔(i=2)</td>
<td>0.487</td>
<td>0.23</td>
<td>1</td>
</tr>
<tr>
<td>大哥(i=3)</td>
<td>0.487</td>
<td>0.23</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>那么第一天是大爷的“概率”：<br>$$ \alpha_{t=1}(1)*\beta_{t=1}(1) = 0.54*0.368=0.19872 $$</p>
<p>第一天是大叔的“概率”：<br>$$ \alpha_{t=1}(2)*\beta_{t=1}(2) = 0.03*0.487=0.01461 $$<br>而第一天不可能是大哥，所以我们可以认为第一天最有可能的是大爷。此处的概率一词加了引号是因为只是形式意义上的一种可能性的表示，但是不满足概率的归一化的要求。<br>以此类推，计算第二天第三天，得到最有可能的后厨序列是：大爷-大叔-大叔。这有什么问题呢？</p>
        
          <p class="article-more-link">
            <a href="../../2017/03/29/机器学习-2017-3-29-ViterbiAlgorithm/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/03/29/机器学习-2017-3-29-ViterbiAlgorithm/" data-id="cjxo5e6rv0041z16daef9msjl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/nlp/">nlp</a></li></ul>

    </footer>
  </div>
  
</article>





  
    

<article id="post-机器学习-2017-3-10-HMM" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="../../2017/03/29/机器学习-2017-3-10-HMM/" class="article-date">
  <time datetime="2017-03-28T16:00:00.000Z" itemprop="datePublished">2017-03-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="../../2017/03/29/机器学习-2017-3-10-HMM/">HMM模型之一(v2.0)</a>
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前我在研一时写的隐马模型系列一因为不知道啥原因，在CSDN上的文章找不到了，然后就也一直没写，这次又看到了HMM，就争取把那篇文章复现出来。而且因为已经是第二次写了，就争取写的深入一些。</p>
<p>HMM有三个基本问题：</p>
<ol>
<li>评估问题：给定模型和两个状态序列，求哪个更有可能。</li>
<li>学习问题：给定观测，求解模型参数。</li>
<li>预测问题：给定模型和观测，求隐状态序列。</li>
</ol>
<p>HMM被定义为一个三元组$$$(A,B,\pi)$$$，$$$\pi$$$表示初始状态概率向量，A表示状态转移概率矩阵，B表示观测概率矩阵。</p>
<p>两个基本假设：</p>
<ol>
<li>齐次马尔科夫性假设：只依赖于前一状态。</li>
<li>观测独立性假设：观测只依赖于状态。</li>
</ol>
<h2 id="前向算法与后向算法"><a href="#前向算法与后向算法" class="headerlink" title="前向算法与后向算法"></a>前向算法与后向算法</h2><h3 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h3><p>刷完了DP算法之后，前向算法其实就很简单了。关键是分解该问题的最优子问题，然后写出递推式。<br>子问题定义为：</p>
<blockquote>
<p>第 i 个隐状态是 i ，生成观测序列的前 t 个元素的概率是多少？</p>
</blockquote>
<p>并将子问题定义为前向变量$$$\alpha_t(i)$$$,那么递推式就可以表示为：<br>$$\alpha_{t+1}(i) = \big[\sum_{j=1}^N\alpha_t^j\big]B(i,o_{t+1})$$</p>
<p>最后输出DP缓存中最后一列的元素和即可。这样的话，该算法的时间复杂度是$$$O(N^2T)$$$，而不是大暴搜的$$$O(N^TT)$$$。</p>
<h3 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h3><p>后向算法的子问题为：</p>
<blockquote>
<p>第 i 个隐状态是 i ，生成观测序列的第 t+1 元素直到最后一个元素的概率是多少？</p>
</blockquote>
<p>并将子问题定义为$$$\beta_t(i)$$$，那么递推式就可以表示为：<br>$$\beta_t(i)=\sum_{j=1}^NA(i,j)B(j,o_{t+1})\beta_{t+1}(j)$$</p>
<p>然后递推变成从前往后了，其实并没有改进算法的效率，这个算法只是为了和前向算法结合去解决后面两个问题的。具体怎么结合呢？</p>
<p>比如说求给定观测序列的概率可以用前向概率和后向概率结合表示：<br>$$P(O|\lambda) = \sum_{i=1}^N\sum_{j=1}^N\alpha_t(i)A(i,j)B(j,o_{t+1})\beta_{t+1}(j)$$</p>
<p>这里引用我自己之前一篇博客中的图片解释</p>
<p><img src="https://img-blog.csdn.net/20170419120654992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY29va2llWlo=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt></p>
<p>那么我们不使用那两个大大的求和符号的话，就可以指定某个向量两个时刻时内部两个隐状态的情况下，求输出概率了。那如果在对其中一个隐状态求边缘概率呢呢？那就可以指定某个时刻下其内部隐状态的情况下求输出概率了。那用这个概率除以$$$P(O|\lambda)$$$呢？那就会得到指定时刻内部状态是某个固定取值的后验概率。这个就是BaumWelch算法中的一个关键计算步骤。注意上面的计算都包含时间t，如果再对时间t求和，那得到的概率就不限制时刻了，而是某个内部状态或者某两个内部状态出现在隐藏序列中的概率。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/03/29/机器学习-2017-3-10-HMM/" data-id="cjxo5e6s00043z16dos10qn9q" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../tags/nlp/">nlp</a></li></ul>

    </footer>
  </div>
  
</article>





  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="../26/">&laquo; 上一页</a><a class="page-number" href="../../">1</a><span class="space">&hellip;</span><a class="page-number" href="../25/">25</a><a class="page-number" href="../26/">26</a><span class="page-number current">27</span><a class="page-number" href="../28/">28</a><a class="extend next" rel="next" href="../28/">下一页 &raquo;</a>
  </nav>


<!-- 文章目录 --> 


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../categories/C/">C++</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/python/">python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/信息安全/">信息安全</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/大数据/">大数据</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/数学/">数学</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/机器学习/">机器学习</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/生活/">生活</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/程序员的玩具/">程序员的玩具</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="../../categories/读书笔记/">读书笔记</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="../../tags/C/">C++</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/algorithm/">algorithm</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/bigdata/">bigdata</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/database/">database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/dataprocessing/">dataprocessing</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/deeplearning/">deeplearning</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/financing/">financing</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/generative/">generative</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hadoop/">hadoop</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hash/">hash</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/hbase/">hbase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/linux/">linux</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/machinelearning/">machinelearning</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/maths/">maths</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/model/">model</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/mysql/">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/nlp/">nlp</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/numpy/">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/python/">python</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/reading/">reading</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/scala/">scala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/security/">security</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/shell/">shell</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/spark/">spark</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/spider/">spider</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/tools/">tools</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/translation/">translation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/trick/">trick</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../tags/web/">web</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="../../tags/C/" style="font-size: 17.69px;">C++</a> <a href="../../tags/algorithm/" style="font-size: 19.23px;">algorithm</a> <a href="../../tags/bigdata/" style="font-size: 15.38px;">bigdata</a> <a href="../../tags/database/" style="font-size: 10px;">database</a> <a href="../../tags/dataprocessing/" style="font-size: 12.31px;">dataprocessing</a> <a href="../../tags/deeplearning/" style="font-size: 13.85px;">deeplearning</a> <a href="../../tags/financing/" style="font-size: 11.54px;">financing</a> <a href="../../tags/generative/" style="font-size: 12.31px;">generative</a> <a href="../../tags/hadoop/" style="font-size: 12.31px;">hadoop</a> <a href="../../tags/hash/" style="font-size: 12.31px;">hash</a> <a href="../../tags/hbase/" style="font-size: 10px;">hbase</a> <a href="../../tags/linux/" style="font-size: 13.85px;">linux</a> <a href="../../tags/machinelearning/" style="font-size: 16.92px;">machinelearning</a> <a href="../../tags/maths/" style="font-size: 16.15px;">maths</a> <a href="../../tags/model/" style="font-size: 11.54px;">model</a> <a href="../../tags/mysql/" style="font-size: 10px;">mysql</a> <a href="../../tags/nlp/" style="font-size: 14.62px;">nlp</a> <a href="../../tags/numpy/" style="font-size: 10px;">numpy</a> <a href="../../tags/python/" style="font-size: 18.46px;">python</a> <a href="../../tags/reading/" style="font-size: 20px;">reading</a> <a href="../../tags/scala/" style="font-size: 10px;">scala</a> <a href="../../tags/security/" style="font-size: 13.85px;">security</a> <a href="../../tags/shell/" style="font-size: 13.08px;">shell</a> <a href="../../tags/spark/" style="font-size: 10.77px;">spark</a> <a href="../../tags/spider/" style="font-size: 10px;">spider</a> <a href="../../tags/tools/" style="font-size: 17.69px;">tools</a> <a href="../../tags/translation/" style="font-size: 10.77px;">translation</a> <a href="../../tags/trick/" style="font-size: 12.31px;">trick</a> <a href="../../tags/web/" style="font-size: 11.54px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/06/">六月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/05/">五月 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/04/">四月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/03/">三月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/02/">二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/11/">十一月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/10/">十月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/07/">七月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/06/">六月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/04/">四月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/03/">三月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/09/">九月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/08/">八月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/07/">七月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/06/">六月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../../2019/06/17/生活-2019-06-17-GTD/">《搞定I——无压工作的艺术》</a>
          </li>
        
          <li>
            <a href="../../2019/05/26/C-2019-05-26-Effective-CPP-IV/">《Effective C++》第四部分：设计和声明</a>
          </li>
        
          <li>
            <a href="../../2019/05/17/C-2019-05-17-Effective-CPP-III/">《Effective C++》第三部分：资源管理</a>
          </li>
        
          <li>
            <a href="../../2019/05/10/机器学习-2019-05-10-alchemy-trick/">仓鼠一般搜集到的炼丹技巧</a>
          </li>
        
          <li>
            <a href="../../2019/05/08/Python-2019-05-08-SICP2/">Python中使用函数构建对象</a>
          </li>
        
      </ul>
    </div>
  </div>

  


  </span>
</aside>

        
      </div>
      <footer id="footer">

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Yongtao Zhang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="../../index.html" class="mobile-nav-link">home</a>
  
    <a href="../../archives" class="mobile-nav-link">archives</a>
  
    <a href="../../about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="../../fancybox/jquery.fancybox.css">
  <script src="../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../js/script.js"></script>



  </div>
</body>
</html>