<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>Hadoop笔记（一） | proTao的大脑具现</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="[TOC] 写在前面一直在上学，所以我接触到的偏工程的项目不是特别多，大部分都是基础而范范的理论。而在这学期的一门大数据系统和大规模数据分析的课程，让我有机会接触到了一部分目前广泛应用于业界的开源项目，这篇文章就是关于第一次课程作业的，也是我的第一篇博文。希望能真真正正的积累一些东西，也算对自己的学习负责。在文章中尽量少涉及概念，主要记录自己的工作。这次的作业内容比较简单，主要是在ubuntu14">
<meta name="keywords" content="bigdata,hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop笔记（一）">
<meta property="og:url" content="https://protao.github.io/2017/03/22/大数据-2017-3-22-HadoopNote-1/index.html">
<meta property="og:site_name" content="proTao的大脑具现">
<meta property="og:description" content="[TOC] 写在前面一直在上学，所以我接触到的偏工程的项目不是特别多，大部分都是基础而范范的理论。而在这学期的一门大数据系统和大规模数据分析的课程，让我有机会接触到了一部分目前广泛应用于业界的开源项目，这篇文章就是关于第一次课程作业的，也是我的第一篇博文。希望能真真正正的积累一些东西，也算对自己的学习负责。在文章中尽量少涉及概念，主要记录自己的工作。这次的作业内容比较简单，主要是在ubuntu14">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-03-15T15:13:06.708Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop笔记（一）">
<meta name="twitter:description" content="[TOC] 写在前面一直在上学，所以我接触到的偏工程的项目不是特别多，大部分都是基础而范范的理论。而在这学期的一门大数据系统和大规模数据分析的课程，让我有机会接触到了一部分目前广泛应用于业界的开源项目，这篇文章就是关于第一次课程作业的，也是我的第一篇博文。希望能真真正正的积累一些东西，也算对自己的学习负责。在文章中尽量少涉及概念，主要记录自己的工作。这次的作业内容比较简单，主要是在ubuntu14">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="../../../../css/style.css">
  <meta name="baidu-site-verification" content="xerEdoxBbf">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)'],['$$$','$$$'],['$','$']]}
});
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../../../index.html" id="logo">proTao的大脑具现</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../../../index.html">home</a>
        
          <a class="main-nav-link" href="../../../../archives">archives</a>
        
          <a class="main-nav-link" href="../../../../about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://protao.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">

<article id="post-大数据-2017-3-22-HadoopNote-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="" class="article-date">
  <time datetime="2017-03-21T16:00:00.000Z" itemprop="datePublished">2017-03-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/大数据/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hadoop笔记（一）
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>[TOC]</p>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a><strong>写在前面</strong></h1><p>一直在上学，所以我接触到的偏工程的项目不是特别多，大部分都是基础而范范的理论。而在这学期的一门大数据系统和大规模数据分析的课程，让我有机会接触到了一部分目前广泛应用于业界的开源项目，这篇文章就是关于第一次课程作业的，也是我的第一篇博文。希望能真真正正的积累一些东西，也算对自己的学习负责。在文章中尽量少涉及概念，主要记录自己的工作。<br>这次的作业内容比较简单，主要是在ubuntu14.04系统上搭建一个伪分布式环境。作业要求是安装JAVA1.7，HADOOP2.6和HBASE0.98。作业内容不难，主要是熟悉环境。</p>
<h1 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a><strong>知识点</strong></h1><ul>
<li><p>HADOOP是一个Apache的开源项目，主要是由两部分构成，分布式文件系统HDFS和分布式计算框架MapReduce这篇文章只涉及到HDFS，暂不考虑MapReduce。</p>
</li>
<li><p>HDFS是GFS的基于Java开源实现，是一个实现在应用层的分布式文件系统，系统架构是master/slave，在HDFS中master是namenode，存放文件的元信息和所在的datanode，slave是datanode，存放真正的数据。出于效率的考虑，对文件不支持修改，只能追加。</p>
</li>
<li><p>由于namenode存储了全部的文件的元信息，宕机的代价无法承担，所以会建立一个secodarynamenode，他可以理解为namenode的一个备份，提供crash recovery。而datanode中一个文件默认有三个备份，所以即使丢失也可以从其他的备份datanode中恢复。</p>
</li>
</ul>
<h1 id="开始动手"><a href="#开始动手" class="headerlink" title="开始动手"></a><strong>开始动手</strong></h1><h2 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a><strong>Ubuntu</strong></h2><p>电脑实在太渣，装在虚拟机里系统卡的蛋疼，所以就装了一个双系统，顺便重温一下很久没用的linux操作系统，没什么可说的。</p>
<h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a><strong>Java</strong></h2><p>java是1.7版本，官网下载，解压，使用<code>sudo vim /etc/profile</code>[^profile]文件中配置环境变量。<br>[^profile]:profile文件：linux是一个多用户操作系统，而在/etc/profile中修改的系统变量是对所有用户都可见的。注销重启后本次修改的系统变量才会生效。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">	#</span><span class="bash">java environment</span></span><br><span class="line">&lt;!-- more --&gt;</span><br><span class="line">	export JAVA_HOME=/usr/lib/jvm/java7</span><br><span class="line">	export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jar</span><br><span class="line">	export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>JAVA_HOME是安装目录。配置后用source<a href="source命令：网上很多教程说使用source命令使当前修改生效。source命令的本意是在当前进程中执行脚本，而正常情况下脚本会在一个子进程中执行。所以使用source命令后在当前进程中系统变量修改时生效的，但是对其他进程是没有用的。">^source</a>生效或者重启，用<code>java -version</code>验证是否配置成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version &quot;1.7.0_79&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</span><br></pre></td></tr></table></figure>
<h2 id="HADOOP"><a href="#HADOOP" class="headerlink" title="HADOOP"></a><strong>HADOOP</strong></h2><p>在官网的下载链接(<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common)中下载你需要的版本。我下载的版本是2.6，注意HADOOP版本要与java版本配套，HADOOP2.7要求至少java1.7，HADOOP2.6要求java至少2.6。" target="_blank" rel="noopener">http://www.apache.org/dyn/closer.cgi/hadoop/common)中下载你需要的版本。我下载的版本是2.6，注意HADOOP版本要与java版本配套，HADOOP2.7要求至少java1.7，HADOOP2.6要求java至少2.6。</a></p>
<p>下载完成后使用<code>tar zxvf hadoop-x.y.x.tar.gz -C /usr/local</code>解压，我的安装目录是/usr/local，如果觉得文件夹名字太长可以重命名。同理在/etc/profile中配置系统变量。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">hadoop environment</span></span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop-2.6.0</span><br><span class="line">export PATH=$PATH:$&#123;HADOOP_HOME&#125;/bin</span><br></pre></td></tr></table></figure></p>
<p>配置环境变量的目的是在任何目录下都可以执行hadoop的命令。但是到这里还没有完全完成。有的教程说要关闭防火墙和在配置hosts文件中配置DNS解析，这里我没有这么配置，直接用的localhost。如果配置好了HADOOP的系统变量，可以简单的在任意一个目录下使用<code>hadoop</code>命令来测试一下，如果提示了帮助信息就说明路径没有问题。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tao@tao-Inspiron-5425:/usr/local/hadoop-2.6.0/sbin$ hadoop</span><br><span class="line">Usage: hadoop [--config confdir] COMMAND</span><br><span class="line">       where COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              print the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  daemonlog            get/set the log level for each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"> or</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure></p>
<p>但是此时只是能正确的找到hadoop命令的所在位置，此时还不能真正的执行，要想能让hadoop服务启动还需要最后几步。<br>然后如果没有安装ssh要安装ssh，这个网上的教程很多了。主要的目的是在集群环境或者伪分布式环境中，如果不用ssh免密码登陆的话，每个进程都需要输入密码。生成公钥并且加入信任列表的话，只有第一次需要用户确认选择yes，之后便可以直接登录。这个也可以不在这里配置，并不影响hadoop的安装，不过也是迟早要完成的。</p>
<p>使用ssh localhost验证是否成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tao@tao-Inspiron-5425:/usr/local$ ssh localhost</span><br><span class="line">Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-66-generic x86_64)</span><br><span class="line"></span><br><span class="line"> * Documentation:  https://help.ubuntu.com</span><br><span class="line"> * Management:     https://landscape.canonical.com</span><br><span class="line"> * Support:        https://ubuntu.com/advantage</span><br><span class="line"></span><br><span class="line">0 个可升级软件包。</span><br><span class="line">0 个安全更新。</span><br><span class="line"></span><br><span class="line">*** System restart required ***</span><br><span class="line">Last login: Mon Mar 20 22:25:59 2017 from 127.0.0.1</span><br><span class="line">tao@tao-Inspiron-5425:~$ exit</span><br><span class="line">注销</span><br><span class="line">Connection to localhost closed.</span><br></pre></td></tr></table></figure></p>
<p>使用exit返回当前环境。然后hadoop还需要改动至少两个地方，一个是hadoop-env.sh，另外一个是几个xml配置文件，都在<code>$HADOOP_HOME/etc/hadoop</code>目录下。<br>首先是hadoop-env.sh:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># The java implementation to use.</span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java7</span><br></pre></td></tr></table></figure></p>
<p>其实我觉得可以不用修改，因为在初始状态这个变量已经指向了${JAVA_HOME}，只要设置好了JAVA_HOME应该就没有问题，不过我还是以防万一改了过来。。。<br>然后是几个配置文件，我先把内容贴出来，再进行说明。</p>
<p><strong>core-site.xml</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>your hostname<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoop-2.6.0/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>hdfs-site.xml</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>mapred-site.xml</strong><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>your hostname<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>解释：</li>
</ul>
<ol>
<li>第一个文件中的fs.default.name是可以访问到你的hdfs的URI，也就是说在将来编写的程序中可以通过hdfs://localhost:9000/来访问你的hdfs；hadoop.tmp.dir的值是hdfs在你本地中的临时目录的存放位置。</li>
<li>第二个文件中dfs.replication是hdfs的冗余备份数，默认是3，由于咱们配置的是伪分布式，不需要额外的冗余也为了防止可能的Error和Warning，在这里改成1。后者顾名思义是禁用文件操作权限检查。</li>
<li>第三个文件的mapred.job.tracker配置的应该是作业跟踪管理器，目前来说应该不配置也可以。</li>
<li>注释：其实在<code>$HADOOP_HOME/share/doc</code>文件夹下有很多hadoop的文档，例如core-site.xml的默认配置和参数描述就在这里<code>$HADOOP_HOME/share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml</code>。按照以上步骤完成后没有意外的话就可以启动hadoop了。</li>
</ol>
<p>在启动服务之前先使用<code>hadoop namenode -format</code>命令格式化namenode。<br>hadoop的启动脚本在<code>$HADOOP_HOME/sbin</code>目录下，使用<code>./start-dfs.sh</code>命令来启动hdfs的相关进程。 然后可以使用jps来查看相关java进程是否启动成功。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tao@tao-Inspiron-5425:/usr/local/hadoop-2.6.0/sbin$ ./start-dfs.sh </span><br><span class="line">Starting namenodes on [localhost]</span><br><span class="line">localhost: starting namenode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-tao-namenode-tao-Inspiron-5425.out</span><br><span class="line">localhost: starting datanode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-tao-datanode-tao-Inspiron-5425.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-tao-secondarynamenode-tao-Inspiron-5425.out</span><br><span class="line"></span><br><span class="line">tao@tao-Inspiron-5425:/usr/local/hadoop-2.6.0/sbin$ jps</span><br><span class="line">3311 NameNode</span><br><span class="line">3619 SecondaryNameNode</span><br><span class="line">3426 DataNode</span><br><span class="line">3739 Jps</span><br></pre></td></tr></table></figure>
<p>可以看到在localhost上面启动了namenode，datanode，和SecondaryNamenode三个进程，相关日志也写入了日志文件。用jps命令也可以看到三个java进程存在。截止至此，hadoop启动成功。<br>我们还可以用其他的方法验证一下hadoop服务能否正常工作。</p>
<ul>
<li><p>使用hadoop shell：在任意文件夹下输入<code>hadoop fs -ls /</code>，这个命令可以查看hdfs的根目录的文件。里面已经存在hbase文件夹是因为我已经在hdfs部署了hbase，这个稍后进行讲解。另外input.tbl是我自己随意上传的测试文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tao@tao-Inspiron-5425:/usr/local/hadoop-2.6.0/sbin$ hadoop fs -ls /</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - tao supergroup          0 2017-03-22 11:04 /hbase</span><br><span class="line">-rw-r--r--   1 tao supergroup        150 2017-03-21 15:45 /input.tbl</span><br></pre></td></tr></table></figure>
</li>
<li><p>另外可以在浏览器中输入localhost:50070<a href="端口：50070是默认的namenode的http服务的端口，所以可以通过浏览器访问。50075是datanode的http服务端口。还有很多其他的默认端口，可查阅hadoop的手册。所有端口基于TCP。">^port</a>查看namenode工作情况。</p>
</li>
</ul>
<h1 id="坑们"><a href="#坑们" class="headerlink" title="坑们"></a><strong>坑们</strong></h1><ul>
<li><p>权限问题：用惯了windows，突然在转到linux下还是比较不太习惯如此明晰的权限管理。一定确保安装之后整个安装文件夹都是属于自己当前用户的。使用ll命令可以检查当前目录下所有文件的详细信息。可以发现hadoop的文件所有者是当前用户tao而不是root。ssh同理也要是在当前用户条件下配置无密码登录，否则就会出现ssh localhost没有问题但是启动进程的时候要求反复输入密码而且还Permission Denied的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">drwxr-xr-x 14 root root 4096 3月  21 10:33 ./</span><br><span class="line">drwxr-xr-x 11 root root 4096 7月  20  2016 ../</span><br><span class="line">drwxr-xr-x  2 root root 4096 3月  17 21:49 bin/</span><br><span class="line">drwxr-xr-x  2 root root 4096 7月  20  2016 etc/</span><br><span class="line">drwxr-xr-x  2 root root 4096 7月  20  2016 games/</span><br><span class="line">drwxr-xr-x 11 tao  root 4096 3月  21 14:42 hadoop-2.6.0/</span><br><span class="line">drwxr-xr-x  8 tao  root 4096 3月  21 10:53 hbase-0.98.24/</span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop namenode -format命令只需要执行一次。在第一次执行后会格式化format文件，在dfs目录下创建name文件夹并管理一个VERSION文件，然后创建datanode后，data文件夹中同样会保存一个VERSION文件，这两个VERSION需要保持一致。</p>
</li>
</ul>
<p><strong>name VERSION</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Thu Mar 23 16:16:20 CST 2017</span><br><span class="line">namespaceID=531037972</span><br><span class="line">clusterID=CID-a03f8986-c3e3-42e4-a094-247c1f3e91e4</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-963905725-127.0.1.1-1490034290631</span><br><span class="line">layoutVersion=-60</span><br></pre></td></tr></table></figure>
<p><strong>data VERSION</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Thu Mar 23 16:16:27 CST 2017</span><br><span class="line">storageID=DS-6084e0ed-0590-4d22-a36f-6c94ef6629e6</span><br><span class="line">clusterID=CID-a03f8986-c3e3-42e4-a094-247c1f3e91e4</span><br><span class="line">cTime=0</span><br><span class="line">datanodeUuid=c5c10d13-0311-4854-8108-5eb9d25b6a50</span><br><span class="line">storageType=DATA_NODE</span><br><span class="line">layoutVersion=-56</span><br></pre></td></tr></table></figure>
<p>发现两者的clusterID要保持一致，如果多次<code>hadoop namenode -format</code>可能导致版本不一样而使得secondaryname或者datanode进程无法启动，查看日志可能会发现有如下信息<code>java.io.IOException: Version Mismatch</code>。<br>此时可能就是这个原因导致的问题，有两种解决办法，一种是手动改动VERSION文件与namenode的VERSION一致，另一种是删除全部文件夹，重新执行<code>hadoop namenode -format</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2017/03/22/大数据-2017-3-22-HadoopNote-1/" data-id="cjxo5e6qx003lz16djxj7s3x2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/bigdata/">bigdata</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/hadoop/">hadoop</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="../../23/大数据-2017-3-23-HBaseNote-1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          HBase初探（一）
        
      </div>
    </a>
  
  
</nav>

  
</article>




</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/C/">C++</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/python/">python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/信息安全/">信息安全</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/大数据/">大数据</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/数学/">数学</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/机器学习/">机器学习</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/生活/">生活</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/程序员的玩具/">程序员的玩具</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/读书笔记/">读书笔记</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/C/">C++</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/algorithm/">algorithm</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/bigdata/">bigdata</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/database/">database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/dataprocessing/">dataprocessing</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/deeplearning/">deeplearning</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/financing/">financing</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/generative/">generative</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hadoop/">hadoop</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hash/">hash</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hbase/">hbase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/linux/">linux</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/machinelearning/">machinelearning</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/maths/">maths</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/model/">model</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/mysql/">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/nlp/">nlp</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/numpy/">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/python/">python</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/reading/">reading</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/scala/">scala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/security/">security</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/shell/">shell</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/spark/">spark</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/spider/">spider</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/tools/">tools</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/translation/">translation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/trick/">trick</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/web/">web</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="../../../../tags/C/" style="font-size: 17.69px;">C++</a> <a href="../../../../tags/algorithm/" style="font-size: 19.23px;">algorithm</a> <a href="../../../../tags/bigdata/" style="font-size: 15.38px;">bigdata</a> <a href="../../../../tags/database/" style="font-size: 10px;">database</a> <a href="../../../../tags/dataprocessing/" style="font-size: 12.31px;">dataprocessing</a> <a href="../../../../tags/deeplearning/" style="font-size: 13.85px;">deeplearning</a> <a href="../../../../tags/financing/" style="font-size: 11.54px;">financing</a> <a href="../../../../tags/generative/" style="font-size: 12.31px;">generative</a> <a href="../../../../tags/hadoop/" style="font-size: 12.31px;">hadoop</a> <a href="../../../../tags/hash/" style="font-size: 12.31px;">hash</a> <a href="../../../../tags/hbase/" style="font-size: 10px;">hbase</a> <a href="../../../../tags/linux/" style="font-size: 13.85px;">linux</a> <a href="../../../../tags/machinelearning/" style="font-size: 16.92px;">machinelearning</a> <a href="../../../../tags/maths/" style="font-size: 16.15px;">maths</a> <a href="../../../../tags/model/" style="font-size: 11.54px;">model</a> <a href="../../../../tags/mysql/" style="font-size: 10px;">mysql</a> <a href="../../../../tags/nlp/" style="font-size: 14.62px;">nlp</a> <a href="../../../../tags/numpy/" style="font-size: 10px;">numpy</a> <a href="../../../../tags/python/" style="font-size: 18.46px;">python</a> <a href="../../../../tags/reading/" style="font-size: 20px;">reading</a> <a href="../../../../tags/scala/" style="font-size: 10px;">scala</a> <a href="../../../../tags/security/" style="font-size: 13.85px;">security</a> <a href="../../../../tags/shell/" style="font-size: 13.08px;">shell</a> <a href="../../../../tags/spark/" style="font-size: 10.77px;">spark</a> <a href="../../../../tags/spider/" style="font-size: 10px;">spider</a> <a href="../../../../tags/tools/" style="font-size: 17.69px;">tools</a> <a href="../../../../tags/translation/" style="font-size: 10.77px;">translation</a> <a href="../../../../tags/trick/" style="font-size: 12.31px;">trick</a> <a href="../../../../tags/web/" style="font-size: 11.54px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/06/">六月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/05/">五月 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/04/">四月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/03/">三月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/02/">二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/11/">十一月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/10/">十月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/07/">七月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/06/">六月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/04/">四月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/03/">三月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/09/">九月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/08/">八月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/07/">七月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/06/">六月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../../../../2019/06/17/生活-2019-06-17-GTD/">《搞定I——无压工作的艺术》</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/26/C-2019-05-26-Effective-CPP-IV/">《Effective C++》第四部分：设计和声明</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/17/C-2019-05-17-Effective-CPP-III/">《Effective C++》第三部分：资源管理</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/10/机器学习-2019-05-10-alchemy-trick/">仓鼠一般搜集到的炼丹技巧</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/08/Python-2019-05-08-SICP2/">Python中使用函数构建对象</a>
          </li>
        
      </ul>
    </div>
  </div>

  


  </span>
</aside>

        
      </div>
      <footer id="footer">

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Yongtao Zhang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="../../../../index.html" class="mobile-nav-link">home</a>
  
    <a href="../../../../archives" class="mobile-nav-link">archives</a>
  
    <a href="../../../../about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.css">
  <script src="../../../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../../../js/script.js"></script>



  </div>
</body>
</html>