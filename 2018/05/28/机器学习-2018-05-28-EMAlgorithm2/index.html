<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>EM算法原理与推导(续) | proTao的大脑具现</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="关于更新参数关于参数如何更新，其实有多种解释都一样，但是为了理清思路，我们要明确一点就是我们即使不对混合模型的对数似然进行任何变化，也是可以做MLE估计的，只是得到的参数最优值不是一个解析式，而是一个涉及到“隐变量”的式子，这才导致我们后续的EM算法并通过迭代方式来最大化似然。用GMM举例子，我们希望极大化： $$ l(\theta)=\sum_{i=1}^mlog\sum_zP(x^{(i)},">
<meta name="keywords" content="tools,machinelearning,maths,algorithm,generative">
<meta property="og:type" content="article">
<meta property="og:title" content="EM算法原理与推导(续)">
<meta property="og:url" content="https://protao.github.io/2018/05/28/机器学习-2018-05-28-EMAlgorithm2/index.html">
<meta property="og:site_name" content="proTao的大脑具现">
<meta property="og:description" content="关于更新参数关于参数如何更新，其实有多种解释都一样，但是为了理清思路，我们要明确一点就是我们即使不对混合模型的对数似然进行任何变化，也是可以做MLE估计的，只是得到的参数最优值不是一个解析式，而是一个涉及到“隐变量”的式子，这才导致我们后续的EM算法并通过迭代方式来最大化似然。用GMM举例子，我们希望极大化： $$ l(\theta)=\sum_{i=1}^mlog\sum_zP(x^{(i)},">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://protao.github.io/img/EM2.png">
<meta property="og:image" content="https://protao.github.io/img/EM3.png">
<meta property="og:updated_time" content="2018-06-05T13:58:41.707Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EM算法原理与推导(续)">
<meta name="twitter:description" content="关于更新参数关于参数如何更新，其实有多种解释都一样，但是为了理清思路，我们要明确一点就是我们即使不对混合模型的对数似然进行任何变化，也是可以做MLE估计的，只是得到的参数最优值不是一个解析式，而是一个涉及到“隐变量”的式子，这才导致我们后续的EM算法并通过迭代方式来最大化似然。用GMM举例子，我们希望极大化： $$ l(\theta)=\sum_{i=1}^mlog\sum_zP(x^{(i)},">
<meta name="twitter:image" content="https://protao.github.io/img/EM2.png">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="../../../../css/style.css">
  <meta name="baidu-site-verification" content="xerEdoxBbf">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)'],['$$$','$$$'],['$','$']]}
});
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../../../index.html" id="logo">proTao的大脑具现</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../../../index.html">home</a>
        
          <a class="main-nav-link" href="../../../../archives">archives</a>
        
          <a class="main-nav-link" href="../../../../about">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://protao.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">

<article id="post-机器学习-2018-05-28-EMAlgorithm2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="" class="article-date">
  <time datetime="2018-05-27T16:00:00.000Z" itemprop="datePublished">2018-05-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      EM算法原理与推导(续)
    </h1>
  
 
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="关于更新参数"><a href="#关于更新参数" class="headerlink" title="关于更新参数"></a>关于更新参数</h2><p>关于参数如何更新，其实有多种解释都一样，但是为了理清思路，我们要明确一点就是我们即使不对混合模型的对数似然进行任何变化，也是可以做MLE估计的，只是得到的参数最优值不是一个解析式，而是一个涉及到“隐变量”的式子，这才导致我们后续的EM算法并通过迭代方式来最大化似然。用GMM举例子，我们希望极大化：</p>
<p>$$ l(\theta)=\sum_{i=1}^mlog\sum_zP(x^{(i)},z^{(i)};\theta)\qquad(1)$$<br>$$=\sum_{i=1}^mlog\sum_k\frac{1}{(2\pi)^{n/2}|\Sigma_i|^{1/2}}exp\Big(-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)\Big)*\phi_k \quad(1.1)$$</p>
<p>这个式子计算的是X被生成的概率，而不考虑来自于哪个组分。我们就啥也不考虑，假设求$$$\mu_k$$$的最优值，直接令其梯度为零，就可以得到：</p>
<p>$$ \sum_{i=1}^m \frac{\phi_k\mathcal{N}(x_i|\mu_k,\Sigma_k)}{\sum_j\phi_j\mathcal{N}(x_i|\mu_j,\Sigma_j)}*\Sigma_k^{-1}(x^{(i)}-\mu_k)=0 \qquad(2)$$<br>$$ \mu_k:=\frac{\sum_{i=1}^mP(z^{(i)}=k|x^{(i)};\mu_k,\Sigma_k)x^{(i)}}{\sum_{i=1}^mP(z^{(i)}=k|x^{(i)};\mu_k,\Sigma_k)} \qquad(2.1)$$</p>
<p>注意（2）中的大的分式就是出现在（2.1）中的后验概率。注意在（2.1）的解的形式，是对数据集中所有数据点的加权平均的方式得到参数的解，后验概率作为其中的权重因子。从感性上看，解的形式很好理解，正常单个的高斯分布参数估计就是求数据点的均值来得到高斯分布的均值参数，而GMM就是以“按劳分配“的方式更新。另外其他的参数更新也可以直接通过对（1.1）的MLE得到。<br>不出意外地，每个参数的估计公式中，都有<strong>reponsibility</strong>的参与，而责任作为后验概率，又依赖于参数，这使得我们清晰的得到EM算法迭代的思路。</p>
<h2 id="期望最大化"><a href="#期望最大化" class="headerlink" title="期望最大化"></a>期望最大化</h2><p>既然这个算法叫期望最大化，那么这里就仔细看看期望在哪，怎么最大化的。<br>其实一切都在<a href="https://protao.github.io/2018/05/27/MachingLearning-2018-05-27-EMAlgorithm/#more">上一篇文章</a>的（9）式中了。还是老生常谈的那句话，这几篇文章中寂静说过很多很多次了，<strong>我们算不了复杂的边缘概率，于是妥协为计算联合分布的概率。但是想算联合分布，我们需要知道人为扩展出来的隐变量，但是我们不知道，所幸我们知道隐变量当前状态下的后验概率。那么好，我们就计算联合分布（的对数）的期望。</strong>这个期望，在PRML一书中，用下式表示：</p>
<p>$$ \mathcal{Q}(\theta, \theta^{old})=\sum_ZP(Z|x,\theta^{old})lnP(x,Z|\theta) \qquad(3)$$<br>$$ \mathcal{Q}(\theta, \theta^{old})=\sum_i\sum_ZP(Z|x^{(i)},\theta^{old})lnP(x^{(i)},Z|\theta) \qquad(3.1)$$<br>（3）是单个数据点的形式，容易推导，（3.1）是全部数据的形式，是真正的期望函数。这个就是我们的算法中核心的期望，也是最大化的目标，我们希望给调整$$$\theta$$$，来最大化这个式子，在M步中$$$\theta^{old}$$$是固定的，后验分布也是固定的。（3.1）式其实和<a href="https://protao.github.io/2018/05/27/MachingLearning-2018-05-27-EMAlgorithm/#more">上一篇文章</a>的（9）和（10）式是一致的。log里的形式不太一样，但是不会影响最终的结果。</p>
<h3 id="举例：伯努利混合模型"><a href="#举例：伯努利混合模型" class="headerlink" title="举例：伯努利混合模型"></a>举例：伯努利混合模型</h3><p><em>参考PRML</em></p>
<p>假设数据是D维向量，该数据的每一个维度来自于一个独立的伯努利分布，然后混合模型来自于K个component的线性组合，此时我们有$$$KD$$$个参数，可以认为$$$\mu_{ij}$$$表示第i个多维伯努利组分的第j维的参数。那么显变量的对数似然为：<br>$$ln(X;\mu,\pi)=\sum_{i=1}^mln\Big( \sum_{k=1}^K\pi_k\prod_{d=1}^D\mu_{kd}^{x_{id}}(1-\mu_{kd})^{1-x_{id}} \Big)$$<br>这个无法直接求解，按照上面叙述的，直接写出E步需要求的后验概率和期望：<br>后验概率：<br>$$ \omega_{nk}=P(z_n=k|x_n;\pi,\mu)=\frac{\pi_kP(x_n|\mu_k)}{\sum_j\pi_jP(x_n|\mu_j)} $$<br>联合分布对数似然的期望:<br>$$ \mathbb{E}_Z\big[lnP(X,Z|\mu,\pi)\big]=\sum_i\sum_Z\omega_{nk}\big(ln\pi_k+\sum_{d=1}^D[x_{id}ln\mu_{kd}+(1-x_{id})ln(1-\mu_{kd})]\big) $$<br>然后M步对其最大化。</p>
<h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> logsumexp</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">p=pathlib.Path(<span class="string">"trainingDigits/"</span>)</span><br><span class="line">cache=[]</span><br><span class="line">label=[]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> p.iterdir():</span><br><span class="line">    <span class="keyword">with</span> open(str(fname),<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cache.append(i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines())</span><br><span class="line">        label.append(int(str(fname.name)[<span class="number">0</span>]))</span><br><span class="line">data=np.array([[list(map(int,line)) <span class="keyword">for</span> line <span class="keyword">in</span> digit] <span class="keyword">for</span> digit <span class="keyword">in</span> cache])</span><br><span class="line">label=np.array(label)</span><br><span class="line"></span><br><span class="line">p=pathlib.Path(<span class="string">"testDigits/"</span>)</span><br><span class="line">cache=[]</span><br><span class="line">answer=[]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> p.iterdir():</span><br><span class="line">    <span class="keyword">with</span> open(str(fname),<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cache.append(i.strip() <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines())</span><br><span class="line">        answer.append(int(str(fname.name)[<span class="number">0</span>]))</span><br><span class="line">test=np.array([[list(map(int,line)) <span class="keyword">for</span> line <span class="keyword">in</span> digit] <span class="keyword">for</span> digit <span class="keyword">in</span> cache])</span><br><span class="line">answer=np.array(answer)</span><br><span class="line"></span><br><span class="line">M = len(data)</span><br><span class="line">D = np.prod(data[<span class="number">0</span>].shape)</span><br><span class="line">K = len(np.unique(label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># initial by label</span></span><br><span class="line">init_mu=[]</span><br><span class="line">init_phi=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">    index=label==i</span><br><span class="line">    labeled_data=data[index].reshape(<span class="number">-1</span>,D)</span><br><span class="line">    init_mu.append(np.sum(labeled_data,axis=<span class="number">0</span>)/len(labeled_data))</span><br><span class="line">    init_phi.append(sum(label==i)/M)</span><br><span class="line"></span><br><span class="line">init_mu=np.array(init_mu)</span><br><span class="line">init_phi=np.array(init_phi)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MixtureBernoulli</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,K,D,M)</span>:</span></span><br><span class="line">        self.K=K <span class="comment"># 组分数</span></span><br><span class="line">        self.D=D <span class="comment"># 数据维度</span></span><br><span class="line">        self.M=M <span class="comment"># 数据规模</span></span><br><span class="line">        self.phi = np.random.ranf((<span class="number">1</span>,K))</span><br><span class="line">        self.phi /= sum(self.phi)</span><br><span class="line">        self.mu = np.random.ranf((K,D))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setPara</span><span class="params">(self, phi=None, mu=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> phi <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">	        self.phi = phi</span><br><span class="line">        <span class="keyword">if</span> mu <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        	self.mu = mu</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_log_bernoulli</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        np.clip(self.mu, <span class="number">1e-10</span>, <span class="number">1</span><span class="number">-1e-10</span>, out=self.mu)</span><br><span class="line">        <span class="keyword">return</span> (X[:,<span class="keyword">None</span>,:]*np.log(self.mu)+(<span class="number">1</span>-X[:,<span class="keyword">None</span>,:])*np.log(<span class="number">1</span>-self.mu)).sum(axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_E_Step</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        responsibility=np.log(self.phi)+self._log_bernoulli(X)</span><br><span class="line">        responsibility -= logsumexp(responsibility, axis=<span class="number">1</span>).reshape((X.shape[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> np.exp(responsibility)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_M_Step</span><span class="params">(self, X, responsibility)</span>:</span></span><br><span class="line">        <span class="comment"># Nk是所有数据点在第k个组分的权重和，所以sum(Nk)=M</span></span><br><span class="line">        Nk = np.sum(responsibility,axis=<span class="number">0</span>).reshape((<span class="number">1</span>,self.K))</span><br><span class="line">        self.mu = ((X.T @ responsibility)/Nk).T</span><br><span class="line">        self.phi=Nk/self.M</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self,X,verbose=False)</span>:</span></span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            old_params = np.hstack((self.phi.ravel(), self.mu.ravel()))</span><br><span class="line">            resp = self._E_Step(X)</span><br><span class="line">            self._M_Step(X, resp)</span><br><span class="line">            <span class="keyword">if</span> np.allclose(old_params, np.hstack((self.phi.ravel(), self.mu.ravel()))):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                print(<span class="string">"iteration &#123;&#125;"</span>.format(i))</span><br><span class="line">                <span class="keyword">if</span> verbose:</span><br><span class="line">                    pred=np.argmax(resp,axis=<span class="number">1</span>)</span><br><span class="line">                    print(pred[:<span class="number">1600</span>].reshape(<span class="number">400</span>,<span class="number">-1</span>)[:,<span class="number">0</span>].reshape((<span class="number">20</span>,<span class="number">20</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify_proba</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        posterior probability of cluster</span></span><br><span class="line"><span class="string">        p(z|x,theta)</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : (sample_size, ndim) ndarray</span></span><br><span class="line"><span class="string">            input</span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        output : (sample_size, n_components) ndarray</span></span><br><span class="line"><span class="string">            posterior probability of cluster</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self._E_Step(X)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        classify input</span></span><br><span class="line"><span class="string">        max_z p(z|x, theta)</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : (sample_size, ndim) ndarray</span></span><br><span class="line"><span class="string">            input</span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        output : (sample_size,) ndarray</span></span><br><span class="line"><span class="string">            corresponding cluster index</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> np.argmax(self.classify_proba(X), axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">mb = MixtureBernoulli(K,D,M)</span><br><span class="line">mb.setPara(phi=init_phi, mu=init_mu)</span><br><span class="line">mb.fit(data.reshape(<span class="number">-1</span>, D),verbose=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">pred=mb.classify(test.reshape(test.shape[<span class="number">0</span>],<span class="number">32</span>*<span class="number">32</span>))</span><br><span class="line">confusion_matrix(pred, answer)</span><br><span class="line"></span><br><span class="line">mu0=mb.mu[<span class="number">0</span>].reshape((<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">plt.imshow(mu0, cmap=<span class="string">"gray"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>最后的分类正确率是87%左右。</p>
<p>还是别人家的代码好啊。注意<code>logsumexp</code>这个函数，我就知道有，但是没找到！然后为了防止下溢出用了对数计算，还有<code>np.clip</code>辅助。多分类问题使用<code>sklearn.metric</code>中的混淆矩阵函数进行直观评估。还有自带的<code>pathlib</code>是好帮手。</p>
<h2 id="EM算法与KL散度"><a href="#EM算法与KL散度" class="headerlink" title="EM算法与KL散度"></a>EM算法与KL散度</h2><p>限制考虑单个数据的情况，因为是对数似然，全部数据集只需要求和。<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4)$$<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(z^{(i)}|x^{(i)};\theta)P(x^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4.1)$$<br>$$J(Q,\theta)=\sum_{z^{(i)}}Q_i(z^{(i)})lnP(x^{(i)};\theta)+\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{P(z^{(i)}|x^{(i)};\theta)}{Q_i(z^{(i)})} \qquad(4.2)$$<br>$$J(Q,\theta)=lnP(x^{(i)};\theta)-KL(Q||P) \qquad(4.3)$$<br>$$lnP(x^{(i)};\theta)=J(Q,\theta)+KL(Q||P) \qquad(4.4)$$</p>
<p>KL散度这里不展开说，只需要知道：KL散度衡量两个分布的距离，P是被衡量的分布，Q是用来拟合的分布，当两个分布一样的时候，KL散度为零。<br>（4.4）式的意义在于，将真正的对数似然拆分成了两部分，第一部分是我们固定$$$\theta$$$构建的下界，第二部分是在$$$\theta$$$处，下界和真正似然的差距。KL距离是一定大于零的，<strong>在给定$$$\theta$$$时</strong>，对数似然可以想（4.4）一样拆成两部分，我们希望下界$$$J$$$尽可能的大，以使得得到最紧的下界，即KL距离尽可能的小，所以必须要让Q分布等于$$$P(z|x;\theta)$$$，于是得到了和第一篇文章中使用Jensen不等式殊途同归的结果。</p>
<p><img src="/img/EM2.png" alt="图1：在$$$\theta$$$上优化对数似然"><br><img src="/img/EM3.png" alt="图2：固定$$$\theta$$$看（4.4）式"></p>
<p>图2的左图表示图1中$$$\theta_{old}$$$经过E步之后，（4.4）式中三个部分的各个状态：在$$$\theta_{old}$$$处，下界紧贴目标函数且KL距离为0的状态。图2的右图表示图1中$$$\theta_{new}$$$的经过M步的状态，即对下界进行优化，得到新的参数估计。此时在图一中花了三条横线，分别对应图2右图中的三条线，<strong>紫色线表示本次E步之前的对数似然，然后从$$$\theta_{old}$$$变成$$$\theta_{new}$$$后，$$$J(Q,\theta)$$$提升到了蓝线的高度，$$$lnP(x^{(i)};\theta)$$$提升到了红线的高度，$$$KL(Q||P)$$$从0变成了蓝红两线的间距</strong>，然后本次的M又会把这个间距缩小成0，以此类推。</p>
<p>参考：</p>
<ol>
<li><a href="https://www.zhihu.com/question/27976634?sort=created" target="_blank" rel="noopener">怎么通俗易懂地解释EM算法并且举个例子?</a></li>
<li><a href="http://www.elecfans.com/d/604076.html" target="_blank" rel="noopener">关于EM算法的九层境界的浅薄介绍，Hinton和Jordan理解的EM算法</a></li>
<li><a href="https://spaces.ac.cn/archives/5239" target="_blank" rel="noopener">从最大似然到EM算法：一致的理解方式</a></li>
<li><a href="https://spaces.ac.cn/archives/4277" target="_blank" rel="noopener">梯度下降和EM算法：系出同源，一脉相承</a></li>
<li>Patttern Recognition and Machine Learning 中译版</li>
<li><a href="https://github.com/ctgk/PRML/blob/master/prml/rv/bernoulli_mixture.py" target="_blank" rel="noopener">PRML读书伴侣ch9</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://protao.github.io/2018/05/28/机器学习-2018-05-28-EMAlgorithm2/" data-id="cjxo5e6su004cz16dm770bgn4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/algorithm/">algorithm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/generative/">generative</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/machinelearning/">machinelearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/maths/">maths</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/tools/">tools</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="../../30/机器学习-2018-05-30-GMM/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          GMM模型原理与实践
        
      </div>
    </a>
  
  
    <a href="../../27/机器学习-2018-05-27-EMAlgorithm/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">EM算法原理与推导</div>
    </a>
  
</nav>

  
</article>




</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/C/">C++</a><span class="category-list-count">25</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/python/">python</a><span class="category-list-count">18</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/信息安全/">信息安全</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/大数据/">大数据</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/数学/">数学</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/机器学习/">机器学习</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/生活/">生活</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/程序员的玩具/">程序员的玩具</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/读书笔记/">读书笔记</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/C/">C++</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/algorithm/">algorithm</a><span class="tag-list-count">34</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/bigdata/">bigdata</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/database/">database</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/dataprocessing/">dataprocessing</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/deeplearning/">deeplearning</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/financing/">financing</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/generative/">generative</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hadoop/">hadoop</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hash/">hash</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/hbase/">hbase</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/linux/">linux</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/machinelearning/">machinelearning</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/maths/">maths</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/model/">model</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/mysql/">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/nlp/">nlp</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/numpy/">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/python/">python</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/reading/">reading</a><span class="tag-list-count">38</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/scala/">scala</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/security/">security</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/shell/">shell</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/spark/">spark</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/spider/">spider</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/tools/">tools</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/translation/">translation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/trick/">trick</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/web/">web</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="../../../../tags/C/" style="font-size: 17.69px;">C++</a> <a href="../../../../tags/algorithm/" style="font-size: 19.23px;">algorithm</a> <a href="../../../../tags/bigdata/" style="font-size: 15.38px;">bigdata</a> <a href="../../../../tags/database/" style="font-size: 10px;">database</a> <a href="../../../../tags/dataprocessing/" style="font-size: 12.31px;">dataprocessing</a> <a href="../../../../tags/deeplearning/" style="font-size: 13.85px;">deeplearning</a> <a href="../../../../tags/financing/" style="font-size: 11.54px;">financing</a> <a href="../../../../tags/generative/" style="font-size: 12.31px;">generative</a> <a href="../../../../tags/hadoop/" style="font-size: 12.31px;">hadoop</a> <a href="../../../../tags/hash/" style="font-size: 12.31px;">hash</a> <a href="../../../../tags/hbase/" style="font-size: 10px;">hbase</a> <a href="../../../../tags/linux/" style="font-size: 13.85px;">linux</a> <a href="../../../../tags/machinelearning/" style="font-size: 16.92px;">machinelearning</a> <a href="../../../../tags/maths/" style="font-size: 16.15px;">maths</a> <a href="../../../../tags/model/" style="font-size: 11.54px;">model</a> <a href="../../../../tags/mysql/" style="font-size: 10px;">mysql</a> <a href="../../../../tags/nlp/" style="font-size: 14.62px;">nlp</a> <a href="../../../../tags/numpy/" style="font-size: 10px;">numpy</a> <a href="../../../../tags/python/" style="font-size: 18.46px;">python</a> <a href="../../../../tags/reading/" style="font-size: 20px;">reading</a> <a href="../../../../tags/scala/" style="font-size: 10px;">scala</a> <a href="../../../../tags/security/" style="font-size: 13.85px;">security</a> <a href="../../../../tags/shell/" style="font-size: 13.08px;">shell</a> <a href="../../../../tags/spark/" style="font-size: 10.77px;">spark</a> <a href="../../../../tags/spider/" style="font-size: 10px;">spider</a> <a href="../../../../tags/tools/" style="font-size: 17.69px;">tools</a> <a href="../../../../tags/translation/" style="font-size: 10.77px;">translation</a> <a href="../../../../tags/trick/" style="font-size: 12.31px;">trick</a> <a href="../../../../tags/web/" style="font-size: 11.54px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/06/">六月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/05/">五月 2019</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/04/">四月 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/03/">三月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/02/">二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/12/">十二月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/11/">十一月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/10/">十月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/07/">七月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/06/">六月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/05/">五月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/04/">四月 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/03/">三月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/02/">二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/11/">十一月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/10/">十月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/09/">九月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/08/">八月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/07/">七月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/06/">六月 2017</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/05/">五月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/04/">四月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/03/">三月 2017</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../../../../2019/06/17/生活-2019-06-17-GTD/">《搞定I——无压工作的艺术》</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/26/C-2019-05-26-Effective-CPP-IV/">《Effective C++》第四部分：设计和声明</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/17/C-2019-05-17-Effective-CPP-III/">《Effective C++》第三部分：资源管理</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/10/机器学习-2019-05-10-alchemy-trick/">仓鼠一般搜集到的炼丹技巧</a>
          </li>
        
          <li>
            <a href="../../../../2019/05/08/Python-2019-05-08-SICP2/">Python中使用函数构建对象</a>
          </li>
        
      </ul>
    </div>
  </div>

  


  </span>
</aside>

        
      </div>
      <footer id="footer">

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Yongtao Zhang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="../../../../index.html" class="mobile-nav-link">home</a>
  
    <a href="../../../../archives" class="mobile-nav-link">archives</a>
  
    <a href="../../../../about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.css">
  <script src="../../../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../../../js/script.js"></script>



  </div>
</body>
</html>